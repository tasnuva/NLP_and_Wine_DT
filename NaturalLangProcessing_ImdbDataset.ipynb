{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose of this project is to determine sentiments from sentences of an Imdb dataset\n",
    "\n",
    "## tool used for data visualization: pandas\n",
    "\n",
    "## tool used for data preprocessing : CountVectorizer method used for feature extraction from the provided dataset\n",
    "\n",
    "## model used for prediction: Many different models are used to determine the accuracy difference among them and find the most efficient one\n",
    "\n",
    "## tools used for data validation: the loss of the model was determined by binary cross entropy and the accruacry was measured by accuracy metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31_A-_DzNIc6"
   },
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MniYJVgkLweS",
    "outputId": "ea61105c-a5ff-442c-f035-d3411ff788da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-11 20:19:21--  https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84188 (82K) [application/x-httpd-php]\n",
      "Saving to: ‘sentiment labelled sentences.zip’\n",
      "\n",
      "sentiment labelled  100%[===================>]  82.21K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-11-11 20:19:22 (796 KB/s) - ‘sentiment labelled sentences.zip’ saved [84188/84188]\n",
      "\n",
      "Archive:  sentiment labelled sentences.zip\n",
      "   creating: sentiment labelled sentences/\n",
      "  inflating: sentiment labelled sentences/.DS_Store  \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/sentiment labelled sentences/\n",
      "  inflating: __MACOSX/sentiment labelled sentences/._.DS_Store  \n",
      "  inflating: sentiment labelled sentences/amazon_cells_labelled.txt  \n",
      "  inflating: sentiment labelled sentences/imdb_labelled.txt  \n",
      "  inflating: __MACOSX/sentiment labelled sentences/._imdb_labelled.txt  \n",
      "  inflating: sentiment labelled sentences/readme.txt  \n",
      "  inflating: __MACOSX/sentiment labelled sentences/._readme.txt  \n",
      "  inflating: sentiment labelled sentences/yelp_labelled.txt  \n",
      "  inflating: __MACOSX/._sentiment labelled sentences  \n"
     ]
    }
   ],
   "source": [
    "def download_data_from_UCI():\n",
    "  !rm -rf 'sentiment labelled sentences'\n",
    "  !rm -rf 'sentiment labelled sentences.zip'\n",
    "  !rm -rf '__MACOSX'\n",
    "  !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\n",
    "  !unzip 'sentiment labelled sentences.zip'\n",
    "\n",
    "download_data_from_UCI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfRagZ0kM_s_",
    "outputId": "57541f16-50bb-4365-a184-3a44db3a2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_cells_labelled.txt  imdb_labelled.txt  readme.txt  yelp_labelled.txt\n"
     ]
    }
   ],
   "source": [
    "!ls 'sentiment labelled sentences'/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pna5eij5YN0b",
    "outputId": "9d68646d-8ca4-4350-e90f-4f8eb93c5e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  \t0\n",
      "Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  \t0\n",
      "Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  \t0\n",
      "Very little music or anything to speak of.  \t0\n",
      "The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.  \t1\n",
      "The rest of the movie lacks art, charm, meaning... If it's about emptiness, it works I guess because it's empty.  \t0\n",
      "Wasted two hours.  \t0\n",
      "Saw the movie today and thought it was a good effort, good messages for kids.  \t1\n",
      "A bit predictable.  \t0\n",
      "Loved the casting of Jimmy Buffet as the science teacher.  \t1\n"
     ]
    }
   ],
   "source": [
    "!head 'sentiment labelled sentences'/imdb_labelled.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "Hu2BZ2iHNvTj",
    "outputId": "c3aac0b4-2657-43f9-cb66-e69e69dda27d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label\n",
       "0    A very, very, very slow-moving, aimless movie ...      0\n",
       "1    Not sure who was more lost - the flat characte...      0\n",
       "2    Attempting artiness with black & white and cle...      0\n",
       "3         Very little music or anything to speak of.        0\n",
       "4    The best scene in the movie was when Gerardo i...      1\n",
       "..                                                 ...    ...\n",
       "743  I just got bored watching Jessice Lange take h...      0\n",
       "744  Unfortunately, any virtue in this film's produ...      0\n",
       "745                   In a word, it is embarrassing.        0\n",
       "746                               Exceptionally bad!        0\n",
       "747  All in all its an insult to one's intelligence...      0\n",
       "\n",
       "[748 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "imdb_df = pd.read_csv('sentiment labelled sentences/imdb_labelled.txt', names=['sentence', 'label'], sep='\\t')\n",
    "imdb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLbrU4IBR7Cf"
   },
   "source": [
    "**Application of Machine Learning on Imdb dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4MqALmjRorb",
    "outputId": "2c875cfe-51ae-4e6e-b9ec-420379216bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imdb Training sentense shape (561,)\n",
      "Imdb Testing sentense shape (187,)\n",
      "Imdb y_data matrix shape (561,)\n",
      "Imdb y_test matrix shape (187,)\n",
      "Imdb sentences_train:  ['Give this one a look.  '\n",
      " 'In fact, this stinker smells like a direct-to-video release.  '\n",
      " 'Every single character was hilarious and deserved to be called a lead.  '\n",
      " 'This movie does an excellent job of revealing the complexity of the task and the incredible challenges facing South Africa.  '\n",
      " 'there are so many problems i dont know where to start.  '\n",
      " 'Judith Light is one of my favorite actresses and I think she does a superb job in this film!  '\n",
      " 'This movie now joins Revenge of the Boogeyman and Zombiez as part of the hellish trinity of horror films.  '\n",
      " \"You can't relate with them, hell you barely can understand them.  \"\n",
      " 'The movie was so boring, that I sometimes found myself occupied peaking in the paper instead of watching (never happened during a Columbo movie before!  '\n",
      " 'The stories were as unbelievable as the actors.  ']\n",
      "Imdb y_train:  [1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1\n",
      " 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
      " 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
      " 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1\n",
      " 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1\n",
      " 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0\n",
      " 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1\n",
      " 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1\n",
      " 1 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "imdb_sentences = imdb_df['sentence'].values\n",
    "imdb_y = imdb_df['label'].values\n",
    "\n",
    "imdb_sentences_train, imdb_sentences_test, imdb_y_train, imdb_y_test = train_test_split(imdb_sentences, imdb_y, test_size=0.25, random_state=42)\n",
    "print(\"Imdb Training sentense shape\", imdb_sentences_train.shape)\n",
    "print(\"Imdb Testing sentense shape\", imdb_sentences_test.shape)\n",
    "print(\"Imdb y_data matrix shape\", imdb_y_train.shape)\n",
    "print(\"Imdb y_test matrix shape\", imdb_y_test.shape)\n",
    "print(\"Imdb sentences_train: \",imdb_sentences_train[0:10])\n",
    "print(\"Imdb y_train: \",imdb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-5pNZuRSDsO",
    "outputId": "25f50c0d-41a9-48d7-f0f8-1b25cb11ba21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (561, 2410)\n",
      "Testing matrix shape (187, 2410)\n",
      "Vocabulary:  {'Give': 229, 'look': 1521, 'In': 282, 'fact': 1156, 'stinker': 2076, 'smells': 2025, 'like': 1500, 'direct': 1004, 'video': 2310, 'release': 1867, 'Every': 179, 'single': 2005, 'character': 819, 'hilarious': 1341, 'deserved': 983, 'called': 784, 'lead': 1482, 'This': 525, 'movie': 1612, 'does': 1030, 'excellent': 1129, 'job': 1438, 'revealing': 1896, 'complexity': 883, 'task': 2147, 'incredible': 1399, 'challenges': 814, 'facing': 1155, 'South': 482, 'Africa': 37, 'problems': 1790, 'dont': 1037, 'know': 1461, 'start': 2067, 'Judith': 304, 'Light': 335, 'favorite': 1183, 'actresses': 616, 'think': 2178, 'superb': 2115, 'film': 1196, 'joins': 1440, 'Revenge': 439, 'Boogeyman': 85, 'Zombiez': 596, 'hellish': 1331, 'trinity': 2224, 'horror': 1360, 'films': 1198, 'You': 594, 'relate': 1860, 'hell': 1330, 'barely': 711, 'understand': 2258, 'The': 518, 'boring': 755, 'occupied': 1659, 'peaking': 1708, 'paper': 1698, 'instead': 1412, 'watching': 2349, 'happened': 1314, 'Columbo': 123, 'stories': 2082, 'unbelievable': 2248, 'actors': 614, 'Think': 524, 'dream': 1048, 'Lassie': 327, 'sleep': 2015, 'FOREVER': 186, 'routine': 1915, 'based': 714, 'TV': 510, 'drama': 1044, 'gets': 1263, 'boost': 751, 'fine': 1201, 'performance': 1714, 'Cole': 122, 'It': 286, 'right': 1902, 'balance': 707, 'war': 2337, 'love': 1533, 'rate': 1832, '10': 0, 'fun': 1244, 'funny': 1247, 'Hopefully': 266, 'director': 1008, 'James': 291, 'Cox': 132, 'turn': 2235, 'short': 1989, 'feature': 1186, 'length': 1488, 'cast': 801, 'win': 2365, 'new': 1638, 'Exceptionally': 184, 'bad': 703, 'practically': 1774, 'perfect': 1712, 'true': 2228, 'masterpiece': 1557, 'sea': 1950, 'faux': 1182, 'masterpieces': 1558, 'Tom': 533, 'Wilkinson': 583, 'man': 1550, 'prepared': 1781, 'ordeal': 1670, 'begin': 721, 'takes': 2138, 'matter': 1560, 'hand': 1307, 'story': 2083, 'progresses': 1799, 'great': 1291, 'actor': 613, 'gives': 1271, 'makes': 1546, 'feel': 1188, 'anguish': 649, 'suffering': 2110, 'Highly': 259, 'entertaining': 1109, 'angles': 648, 'just': 1448, 'adorable': 623, 'seeing': 1956, 'Mickey': 368, 'playing': 1742, 'Turkey': 548, 'Straw': 497, 'highly': 1340, 'imaginative': 1383, 'occasionally': 1658, 'cruel': 940, 'way': 2351, 'DELETE': 137, 'mind': 1584, 'definitely': 968, 'cult': 941, 'classic': 850, 'worth': 2385, 'viewing': 2313, 'sharing': 1980, 'music': 1618, 'really': 1845, 'nice': 1639, 'football': 1225, 'scenes': 1937, 'end': 1094, 'perplexing': 1717, 'Shot': 468, 'Southern': 483, 'California': 103, 'desert': 982, 'using': 2293, 'patent': 1705, 'documentary': 1029, 'style': 2097, 'Watkins': 570, 'creates': 933, 'Definitely': 146, 'checking': 829, 'Very': 559, 'relaxing': 1866, 'late': 1474, 'night': 1640, 'Oh': 399, 'yeah': 2400, 'storyline': 2084, 'pathetic': 1706, 'terribly': 2168, 'disappointed': 1010, 'receive': 1848, 'awards': 693, 'accolades': 604, 'especially': 1119, 'far': 1171, 'deserving': 985, 'works': 2380, 'Totally': 540, 'different': 1001, 'loads': 1515, 'understatement': 2260, 'black': 736, 'comedy': 866, 'remember': 1874, 'Even': 178, 'women': 2368, 'finally': 1200, 'sign': 1997, 'improvement': 1391, 'expected': 1140, 'things': 2177, 'happen': 1313, 'time': 2195, 'asleep': 673, 'All': 42, 'make': 1543, 'sick': 1996, 'slackers': 2014, 'excuses': 1135, 'stupid': 2095, 'actions': 612, '90': 28, 'minutes': 1589, 'Personally': 419, 'shows': 1994, 'people': 1711, 'learn': 1485, 'compromise': 887, 'self': 1959, 'involving': 1431, 'issue': 1434, 'Considering': 127, 'relations': 1863, 'screen': 1942, 'Taylor': 513, 'Stanwyck': 488, 'surprising': 2126, 'little': 1510, 'chemistry': 834, 'll': 1514, 'Angel': 50, 'beautiful': 718, 'Scamp': 451, 'His': 262, 'yelps': 2403, 'hes': 1336, 'scared': 1932, 'funniest': 1246, 'parts': 1703, 'caught': 805, 'curtain': 943, 'singing': 2004, 'Ive': 288, 'Never': 387, 'Had': 244, 'Feeling': 193, 'Before': 73, 'totally': 2208, 'recommend': 1851, 'coming': 871, 'special': 2046, 'edition': 1073, 'June': 306, '20': 14, 'cover': 924, 'scamp': 1931, 'garbage': 1252, 'underneath': 2256, 'lid': 1495, 'CG': 99, 'opening': 1668, 'sequence': 1968, 'space': 2044, 'looked': 1522, 'created': 932, 'Microsoft': 369, 'Slideshow': 474, 'God': 232, 'sake': 1922, 'deserves': 984, 'strong': 2089, 'kudos': 1464, 'taking': 2139, 'stand': 2061, 'having': 1322, 'exceptional': 1130, 'acting': 610, 'lesser': 1489, 'known': 1462, 'super': 2114, 'intelligent': 1420, 'script': 1946, 'doesn': 1031, 'insult': 1415, 'audience': 687, 'easy': 1068, 'comes': 867, 'white': 2360, 'racism': 1827, 'came': 786, 'free': 1236, 'DVD': 139, 'player': 1740, 'bought': 758, 'turned': 2236, 'thing': 2176, 'halfway': 1305, 'embarrassed': 1084, 'Howell': 271, 'But': 96, 'duet': 1058, 'astronaut': 679, 'doctor': 1027, 'beginning': 722, 'exchange': 1133, 'considers': 898, 'Cold': 121, 'War': 567, 'biggest': 732, 'fear': 1185, 'crashed': 928, 'USSR': 552, 'couldn': 920, 'seriously': 1970, 'interplay': 1425, 'Martin': 361, 'Emilio': 169, 'contains': 902, 'wonderful': 2372, 'saw': 1927, 'Wall': 566, 'Street': 498, 'Charlie': 115, 'Avoid': 64, 'costs': 919, 'If': 279, 'probably': 1789, 'leave': 1486, 'shelf': 1983, 'One': 403, 'worst': 2384, 'For': 203, 'awful': 696, 'dialogue': 996, 'hopeless': 1356, 'overacting': 1676, 'shot': 1991, 'real': 1840, 'waste': 2342, 'Despite': 147, 'pans': 1696, 'reviewers': 1899, 'liked': 1501, 'Don': 155, 'rubbish': 1916, 'non': 1642, 'researched': 1889, 'To': 531, 'masterful': 1556, 'say': 1928, 'intelligence': 1419, 'imagination': 1382, 'obviously': 1657, 'used': 2291, 'try': 2230, 'sense': 1962, 'pitiful': 1732, 'attempt': 683, 'human': 1368, 'nature': 1627, 'involved': 1429, 'includes': 1395, 'Shatner': 464, 'Nimoy': 389, 'washed': 2340, 'making': 1547, 'old': 1665, 'life': 1497, 'effects': 1077, 'tacky': 2136, 'Spock': 487, 'rescue': 1888, 'Kirk': 313, 'jet': 1437, 'pack': 1689, 'falls': 1164, 'mountain': 1607, 'walked': 2331, 'faster': 1178, 'HBO': 240, 'day': 956, 'absolutely': 600, 'loved': 1534, 'Much': 377, 'interesting': 1423, 'action': 611, 'suspense': 2129, 'unneeded': 2277, 'controversy': 909, 'littered': 1509, 'overt': 1682, 'racial': 1826, 'slurs': 2021, 'members': 1572, 'return': 1895, 'whites': 2361, 'depicted': 976, 'morons': 1605, 'boobs': 749, 'don': 1036, 'got': 1285, 'shelves': 1985, 'store': 2081, 'watch': 2346, 'long': 1519, 'losing': 1527, 'spoilers': 2055, 'huge': 1367, 'disappointment': 1012, 'painful': 1691, 'let': 1490, 'girlfriend': 1269, 'talk': 2144, 'idea': 1373, 'hated': 1319, 'From': 212, 'Widmark': 582, 'turns': 2237, 'unintentionally': 2268, 'comical': 870, 'original': 1672, 'Body': 84, 'Soul': 481, '1947': 6, 'aerial': 626, 'NOBODY': 382, 'identifies': 1375, 'characters': 821, 'cardboard': 794, 'cutouts': 947, 'stereotypes': 2074, 'predictably': 1777, 'reverse': 1897, 'Everything': 180, 'appalling': 657, 'Really': 437, 'scary': 1934, 'No': 390, 'plot': 1749, 'whatsoever': 2358, 'paid': 1690, 'He': 251, 'unbearable': 2247, 'charisma': 822, 'terrible': 2167, 'comedic': 865, 'timing': 2200, 'fantastic': 1170, 'seamlessly': 1952, 'woven': 2391, 'dogs': 1032, 'splendid': 2051, 'rent': 1880, 'view': 2311, 'ceases': 807, 'simply': 2002, 'keeps': 1450, 'alert': 638, 'decipher': 963, 'meanings': 1566, 'exquisite': 1149, 'visual': 2319, 'composition': 885, 'moment': 1597, 'inventive': 1428, 'elegant': 1082, 'use': 2290, 'close': 858, 'camera': 788, 'angle': 647, 'lighting': 1499, 'including': 1396, 'pointillistic': 1754, 'home': 1351, 'footage': 1224, 'wonder': 2370, 'joy': 1444, 'behold': 723, 'Christmas': 117, 'showed': 1993, 'lot': 1529, 'Florida': 201, 'best': 728, 'appealing': 658, 'Too': 537, 'politically': 1759, 'correct': 917, 'predictable': 1776, 'chick': 835, 'flick': 1214, 'cutting': 949, 'edge': 1071, 'Hated': 248, 'How': 269, 'piece': 1729, 'trash': 2219, 'released': 1868, 'supposedly': 2122, 'ALL': 29, 'wrong': 2397, 'thought': 2181, 'awesome': 695, 'Ebay': 163, 'Julian': 305, 'Fellowes': 195, 'triumphed': 2226, 'advise': 625, 'Elias': 168, 'Koteas': 315, 'Jack': 289, 'Palance': 412, 'play': 1738, 'good': 1281, 'roles': 1910, 'Angelina': 52, 'hot': 1362, 'naked': 1620, 'Billy': 82, 'Drago': 158, 'appears': 660, 'cool': 914, 'usual': 2294, 'cameo': 787, 'Sven': 503, 'ole': 1666, 'Thorsen': 526, 'helps': 1334, 'enjoyable': 1104, 'decent': 962, 'budget': 777, 'success': 2106, 'depends': 975, 'casting': 803, 'Sydney': 504, 'Greenstreet': 237, 'Alexander': 41, 'Yardley': 591, 'That': 517, 'painfully': 1692, 'dreary': 1050, 'waster': 2344, 'IQ': 277, 'particularly': 1702, 'mollusk': 1596, 'looks': 1524, 'rough': 1914, 'draft': 1043, 'written': 2396, 'shooting': 1988, 'began': 720, 'finished': 1204, 'completed': 880, 'child': 836, '1973': 9, 'Stranger': 496, 'average': 689, 'main': 1540, 'person': 1718, 'low': 1536, 'clearly': 852, 'lacks': 1468, 'scares': 1933, 'tension': 2163, 'medical': 1567, 'terminology': 2165, 'bit': 734, 'iffy': 1380, 'insulin': 1414, 'dependant': 974, 'diabetic': 994, 'wasn': 2341, 'expecting': 1141, 'Oscar': 406, 'material': 1559, 'Instead': 283, 'bore': 753, 'fest': 1194, 'whiny': 2359, 'spoiled': 2053, 'brat': 763, 'babysitting': 701, 'sort': 2040, 'pap': 1697, 'screened': 1943, 'afternoon': 630, 'punish': 1814, 'unemployed': 2264, 'jobs': 1439, 'Omit': 401, 'Director': 151, 'Paul': 416, 'Matthews': 364, 'wrote': 2398, 'directed': 1005, 'weak': 2354, '1995': 12, 'monster': 1602, 'Grim': 238, 'pace': 1686, 'hope': 1355, 'team': 2152, 'movies': 1613, 'continue': 904, 'kinda': 1459, 'weird': 2356, 'peculiarity': 1709, 'Loved': 344, 'Jimmy': 298, 'Buffet': 93, 'science': 1939, 'teacher': 2150, 'believe': 725, 'screenwriter': 1945, 'did': 998, 'tying': 2241, 'loose': 1525, 'ends': 1099, 'Overall': 407, 'provoking': 1808, 'Only': 404, 'buildings': 780, 'couple': 921, 'locations': 1517, 'MAYBE': 350, 'poor': 1761, 'hummh': 1369, 'They': 522, 'identify': 1376, 'need': 1630, 'memorized': 1575, 'She': 465, 'lovely': 1535, 'cutie': 946, 'memories': 1574, 'murky': 1617, 'enjoyed': 1105, 'episode': 1113, 'product': 1796, 'related': 1861, 'struggle': 2091, 'timers': 2198, 'Predictable': 429, 'Again': 39, 'Errol': 175, 'Flynn': 202, 'brilliant': 769, 'dads': 950, 'favourite': 1184, 'grew': 1294, 'scenery': 1936, 'daughters': 955, 'paint': 1693, 'photograph': 1722, 'forces': 1226, 'question': 1820, 'threshold': 2185, 'loneliness': 1518, 'portrayal': 1764, 'family': 1166, 'share': 1979, 'ups': 2288, 'knew': 1460, 'literally': 1508, 'excerpts': 1131, 'Star': 489, 'Trek': 543, 'final': 1199, 'Frontier': 213, 'series': 1969, 'drive': 1054, 'barking': 712, 'mad': 1538, 'guess': 1299, 'network': 1637, 'aired': 637, 'dribble': 1051, 'watched': 2348, 'putting': 1816, 'Being': 74, 'truly': 2229, 'proudly': 1806, 'big': 731, 'classical': 851, 'WB': 562, 'cartoons': 799, 'composed': 884, 'However': 272, 'didn': 999, 'overall': 1677, 'tremendously': 2222, 'delight': 969, 'After': 38, 'wanted': 2334, 'artist': 668, 'cheap': 827, 'cheerless': 832, 'heist': 1329, 'characterisation': 820, 'lots': 1530, 'underbite': 2254, 'stoic': 2080, 'emoting': 1087, 'Chow': 116, 'Yun': 595, 'Fat': 191, 'Better': 78, 'Tomorrow': 534, 'cheesy': 833, 'clichés': 855, 'thrown': 2190, 'abandoned': 597, 'factory': 1157, 'ready': 1839, 'poorly': 1762, 'executed': 1136, 'flying': 1217, 'judo': 1446, 'rolls': 1912, 'la': 1465, 'John': 299, 'Woo': 586, 'setting': 1974, 'possible': 1768, 'redeemed': 1854, 'MST3K': 352, 'fodder': 1219, 'year': 2401, 'reminded': 1875, 'Huston': 275, 'game': 1250, 'evinced': 1126, 'faithful': 1161, 'adaptation': 618, 'Joyce': 302, 'acclaimed': 603, 'novella': 1649, 'Dead': 143, 'premise': 1780, 'sound': 2041, 'Lange': 326, 'actress': 615, 'Lifetime': 334, 'air': 636, 'knows': 1463, 'sells': 1960, 'soundtrack': 2043, 'slow': 2020, 'moving': 1614, 'aimless': 635, 'distressed': 1024, 'drifting': 1053, 'young': 2404, 'Fans': 190, 'genre': 1260, 'heaven': 1327, 'steve': 2075, 'martin': 1553, 'delivers': 973, 'middle': 1582, 'aged': 632, 'upper': 2287, 'class': 849, 'uptight': 2289, 'guy': 1302, 'sorry': 2039, 'What': 577, 'volcano': 2325, 'Los': 341, 'Angeles': 51, 'About': 31, '30': 19, 'wasted': 2343, 'mediocre': 1568, 'elderly': 1081, 'awkwardly': 697, 'babbling': 700, 'overwrought': 1683, 'pseudo': 1809, 'Satanic': 449, 'gibberish': 1266, 'corny': 916, 'teen': 2156, 'Goth': 233, 'blush': 742, 'Olde': 400, 'English': 172, 'Latin': 329, 'words': 2377, 'Foreigner': 204, 'second': 1954, 'wish': 2366, 'enter': 1107, 'negative': 1633, 'values': 2298, 'admins': 621, 'miserable': 1590, 'hollow': 1350, 'laughable': 1478, 'want': 2333, 'hosting': 1361, 'voice': 2323, 'overs': 1681, 'monotonous': 1601, 'guests': 1300, 'derivative': 980, 'ending': 1097, 'mercy': 1579, 'killing': 1456, 'kind': 1458, 'idiot': 1377, 'produce': 1792, 'mess': 1581, 'place': 1733, 'mention': 1578, 'season': 1953, 'Lame': 323, 'telephone': 2159, 'repair': 1881, 'reactions': 1836, 'nuts': 1654, 'bitchy': 735, 'boss': 756, 'genuine': 1262, 'said': 1921, 'better': 729, 'situations': 2012, 'played': 1739, 'coach': 861, 'fascinating': 1174, 'Paolo': 413, 'Sorrentino': 480, 'Tony': 536, 'built': 781, 'unforgettable': 2266, 'seen': 1957, 'recent': 1849, 'years': 2402, 'Plus': 426, 'modest': 1595, 'fast': 1177, 'running': 1918, 'amazing': 643, 'Whatever': 578, 'producer': 1794, 'going': 1278, 'missed': 1593, 'entirely': 1111, 'transfers': 2216, 'started': 2068, 'thoughts': 2182, 'convincing': 912, 'Lane': 325, 've': 2300, 'lousy': 1531, 'recently': 1850, 'Fox': 206, 'Movie': 375, 'Channel': 113, 'Having': 249, 'humour': 1372, 'apt': 663, 'money': 1599, 'Mark': 360, 'Evil': 181, 'Phantasm': 421, 'discovering': 1015, 'falling': 1163, '40': 20, 'line': 1504, 'Still': 494, 'empowerment': 1091, 'Hayao': 250, 'Miyazaki': 371, 'latest': 1475, 'eighth': 1079, 'Studio': 500, 'Ghibili': 225, 'Gake': 218, 'Ue': 553, 'Ponyo': 427, 'Cliff': 120, 'Sea': 457, 'wonderfully': 2373, 'childhood': 837, 'Then': 519, 'Sundays': 501, 'ago': 634, 'March': 357, '20th': 17, '2005': 15, 'enjoy': 1103, 'taped': 2146, 'entire': 1110, 'bring': 771, 'pillow': 1731, 'boyfriend': 760, 'mature': 1561, 'subtle': 2104, 'suggests': 2112, 'brings': 772, 'dramatic': 1045, 'focus': 1218, 'underlying': 2255, 'tensions': 2164, 'served': 1971, 'performances': 1715, 'apart': 656, 'odd': 1662, 'inappropriate': 1393, 'smiling': 2027, 'Keira': 310, 'Knightley': 314, 'prone': 1802, 'direction': 1007, 'Not': 392, 'elaborately': 1080, 'aesthetically': 627, 'sculpture': 1949, 'unconditional': 2250, 'Tiny': 529, 'Toons': 538, 'kept': 1451, 'vibe': 2309, 'delivered': 971, 'popular': 1763, 'underrated': 2257, 'poler': 1757, 'bear': 717, 'cute': 944, 'Fort': 205, 'Steele': 491, 'ask': 672, 'away': 694, 'Duris': 159, 'wholesome': 2362, 'appearance': 659, 'ultra': 2244, 'terrific': 2169, 'art': 666, 'crayon': 929, 'pencil': 1710, 'drawings': 1046, 'colorful': 863, 'fanciful': 1168, 'SO': 445, 'shed': 1981, 'tear': 2153, 'thrilled': 2186, 'forget': 1228, 'CLASSIC': 101, 'Which': 580, 'depth': 979, 'Malta': 354, 'settings': 1975, 'dry': 1057, 'barren': 713, 'hockey': 1346, 'defensemen': 967, 'goalies': 1275, 'diving': 1026, 'shots': 1992, 'feet': 1190, 'wide': 2363, 'net': 1636, 'haven': 1321, 'ridiculous': 1901, 'Started': 490, 'particular': 1701, 'relationship': 1864, 'bakery': 706, 'assistant': 677, 'waitress': 2329, 'work': 2378, 'superficial': 2117, 'gave': 1253, 'feeling': 1189, 'stagey': 2060, 'stage': 2059, 'farce': 1172, 'By': 98, 'pyromaniac': 1818, 'waylaid': 2352, 'bored': 754, 'care': 795, 'switched': 2133, 'Glad': 230, 'pay': 1707, 'Didn': 150, 'laugh': 1477, 'smile': 2026, 'yawn': 2399, 'educational': 1074, 'children': 838, 'Barney': 70, 'DE': 136, 'duper': 1062, 'pretty': 1786, 'Babie': 69, 'Bop': 86, 'kids': 1454, 'Storm': 495, 'Trooper': 545, 'list': 1507, 'unrecommended': 2284, 'Just': 307, 'avoid': 691, 'Groove': 239, 'antithesis': 655, 'Human': 274, 'Traffic': 542, 'fails': 1159, 'create': 931, 'sets': 1973, 'designed': 986, 'stylized': 2098, 'effective': 1076, 'Schrader': 452, 'Mishima': 370, 'complex': 882, 'conclusion': 891, 'bother': 757, 'nonsense': 1644, 'Anyway': 56, 'flowed': 1216, 'smoothly': 2028, 'male': 1548, 'bonding': 746, 'hoot': 1354, 'Final': 198, 'Word': 587, 'Show': 470, 'torture': 2206, 'People': 417, 'European': 177, 'So': 477, 'enjoyment': 1106, 'run': 1917, 'games': 1251, 'dangerous': 953, 'Raw': 436, 'sublimely': 2101, 'features': 1187, 'outlandish': 1674, 'array': 665, 'memorable': 1573, 'psychotic': 1810, 'lovable': 1532, 'witty': 2367, 'delightful': 970, 'Dr': 157, 'Seuss': 461, 'book': 750, 'brilliantly': 770, 'animated': 651, 'UPA': 551, 'finest': 1202, 'thoroughly': 2180, 'Academy': 32, 'Award': 65, 'horrible': 1358, 'cause': 806, 'BAD': 66, 'Actors': 35, 'period': 1716, 'structure': 2090, 'easily': 1067, 'tightly': 2194, 'constructed': 901, 'history': 1344, 'cinema': 845, 'vitally': 2320, 'important': 1386, 'occurs': 1661, 'minute': 1588, 'content': 903, 'level': 1493, 'dozen': 1042, 'quite': 1824, 'highest': 1339, 'superlative': 2118, 'form': 1233, 'imaginable': 1381, 'Yes': 593, 'require': 1887, 'significant': 1998, 'puzzle': 1817, 'solving': 2033, 'pieces': 1730, 'fit': 1208, 'picture': 1727, 'certainly': 812, 'pulls': 1812, 'punches': 1813, 'Graphics': 235, 'number': 1650, 'TH': 505, 'insane': 1405, 'There': 520, 'massive': 1555, 'levels': 1494, 'unlockable': 2273, 'Waste': 569, 'properly': 1804, 'Actually': 36, 'graphics': 1288, 'Today': 532, 'crap': 927, 'As': 60, 'Canada': 105, 'aye': 698, 'rocks': 1908, 'Buy': 97, 'PURE': 411, 'BRILLIANCE': 68, 'doomed': 1038, 'conception': 890, 'lame': 1471, 'minor': 1587, 'PG': 408, '13': 2, 'complete': 879, 'sequel': 1966, 'changing': 818, 'tone': 2205, 'rated': 1833, 'interested': 1422, 'confirm': 892, 'unfunny': 2267, 'generic': 1258, 'managed': 1551, 'ENTIRE': 161, 'exaggerating': 1128, 'point': 1753, 'joke': 1441, 'told': 2203, 'trailer': 2214, 'talented': 2142, 'Carrell': 110, 'save': 1926, 'stars': 2066, 'fare': 1173, 'Morgan': 373, 'Freeman': 209, 'Jonah': 300, 'Hill': 261, 'Ed': 165, 'Helms': 254, 'lazy': 1481, 'presence': 1782, 'animals': 650, 'integration': 1418, 'obvious': 1656, 'blue': 741, 'green': 1293, 'cost': 918, 'translate': 2217, 'quality': 1819, 'sure': 2123, 'succeeds': 2105, 'despite': 990, 'meagre': 1562, 'glad': 1272, 'choice': 840, 'addition': 620, 'songs': 2037, 'French': 210, 'Cancan': 106, 'boasts': 743, 'cutest': 945, 'leading': 1483, 'ladies': 1469, 'grace': 1286, 'hard': 1316, 'fall': 1162, 'head': 1323, 'heels': 1328, 'girl': 1268, 'On': 402, 'insipid': 1407, 'regret': 1858, 'hours': 1364, 'Long': 338, 'pointless': 1755, 'waiting': 2328, 'future': 1248, 'efforts': 1078, 'Excellent': 182, 'believable': 724, 'Anne': 55, 'Heche': 252, 'utterly': 2296, 'Sam': 447, 'Shepard': 466, 'gung': 1301, 'ho': 1345, 'Marine': 358, 'sobering': 2029, 'sat': 1925, 'riveted': 1905, 'resounding': 1890, 'Hanks': 246, 'reading': 1838, 'annoying': 654, 'fingernails': 1203, 'chalkboard': 813, 'unnecessary': 2276, 'train': 2215, 'roller': 1911, 'coaster': 862, 'scene': 1935, 'warmth': 2338, 'charm': 824, 'grates': 1290, 'nerves': 1634, 'improved': 1390, 'improvisation': 1392, 'twice': 2238, 'worry': 2382, 'delivering': 972, 'And': 49, 'honestly': 1353, 'Often': 398, 'follow': 1220, 'surroundings': 2128, 'crackles': 925, 'unpredictable': 2281, 'youthful': 2406, 'energy': 1101, 'concentrate': 889, 'meanders': 1564, 'badly': 704, 'generally': 1257, 'wouldn': 2389, 'builders': 779, 'cross': 938, 'cliche': 854, 'choices': 841, 'parents': 1700, 'predict': 1775, 'dialog': 995, 'verbatim': 2303, 'writing': 2395, 'selections': 1958, 'gross': 1296, 'chills': 839, 'Nevsky': 388, 'lived': 1511, 'pretentious': 1784, 'planned': 1736, 'Dodge': 154, 'stratus': 2087, 'Big': 81, 'Shots': 469, 'gonna': 1280, 'help': 1332, 'makers': 1545, 'aren': 664, 'restrained': 1892, 'business': 783, 'Québec': 433, 'jerky': 1436, 'movements': 1610, 'Things': 523, 'personalities': 1719, 'change': 816, 'twists': 2240, 'occur': 1660, 'reason': 1846, 'calls': 785, 'Matrix': 363, 'sequels': 1967, 'appreciate': 662, 'mindblowing': 1585, 'experience': 1142, 'Songs': 479, 'Were': 576, 'Best': 77, 'Muppets': 378, 'Hilarious': 260, 'rest': 1891, 'early': 1065, 'goremeister': 1283, 'Lucio': 346, 'Fulci': 214, 'giallo': 1265, 'sub': 2099, 'weren': 2357, 'forgetting': 1230, 'looking': 1523, 'Shirley': 467, 'Jones': 301, 'rendition': 1878, 'Way': 572, 'Look': 339, 'Tonight': 535, 'uplifting': 2286, 'charismatic': 823, '15': 3, 'humorous': 1371, 'comment': 872, '2006': 16, 'Angus': 53, 'Scrimm': 456, 'somewhat': 2034, 'brief': 766, 'role': 1909, 'gently': 1261, 'menacing': 1577, 'violin': 2316, 'anatomist': 646, 'Doctor': 153, 'Quinn': 432, 'squibs': 2058, 'fresh': 1238, 'sublime': 2100, 'effect': 1075, 'shameful': 1978, 'handles': 1310, 'tough': 2212, 'issues': 1435, 'dignity': 1002, 'course': 922, 'shocking': 1987, 'spoiler': 2054, 'wouldnt': 2390, 'redeeming': 1855, 'realised': 1841, 'actually': 617, 'Let': 332, 'professor': 1798, 'An': 48, 'instant': 1411, 'catchy': 804, 'song': 2036, 'credits': 937, 'Some': 478, 'applause': 661, 'given': 1270, 'prelude': 1779, 'perfectly': 1713, 'ways': 2353, 'modern': 1594, 'equivalent': 1115, 'Dickens': 149, 'Carol': 109, 'sensibility': 1963, 'blew': 739, 'Hackneyed': 243, 'worse': 2383, 'directing': 1006, 'gem': 1256, 'terms': 2166, 'screenplay': 1944, 'cinematography': 847, 'post': 1769, 'production': 1797, 'editing': 1072, 'aspect': 674, 'national': 1623, 'treasure': 2221, 'zillion': 2408, 'times': 2199, 'reality': 1842, 'camp': 789, 'value': 2297, 'inspiration': 1409, 'come': 864, 'overcome': 1678, 'rejection': 1859, 'Italian': 287, 'thrillers': 2188, '70': 23, 'At': 62, 'animation': 652, 'dominated': 1035, 'Disney': 152, 'Pixar': 424, 'CGI': 100, 'refreshing': 1857, 'comforting': 869, 'relying': 1870, 'traditional': 2213, 'drawn': 1047, 'tell': 2160, 'charming': 825, 'enchanting': 1093, 'Here': 257, 'Wind': 584, 'Lion': 337, 'rendering': 1877, 'America': 45, 'Imperial': 281, 'age': 631, 'Artless': 59, 'endlessly': 1098, 'presents': 1783, 'ugliest': 2242, 'holds': 1348, 'attention': 685, 'Emily': 170, 'Watson': 571, 'Horrible': 267, 'UNfunny': 550, 'unrealistic': 2282, 'utter': 2295, '70000': 24, 'Later': 328, 'lost': 1528, 'power': 1771, 'entertained': 1108, 'details': 992, 'dysfunction': 1063, 'dull': 1059, 'uninteresting': 2269, 'forgettable': 1229, 'secondary': 1955, 'incomprehensible': 1397, 'relation': 1862, 'primary': 1788, 'mystifying': 1619, 'wooden': 2375, 'puppets': 1815, 'picked': 1726, 'speed': 2047, 'meaning': 1565, 'emptiness': 1092, 'house': 1365, 'small': 2023, 'consolations': 900, 'sisters': 2008, 'completely': 881, 'Titta': 530, 'Di': 148, 'Girolamo': 228, 'stay': 2070, 'vision': 2318, 'horrified': 1359, 'sympathetic': 2134, 'review': 1898, 'overdue': 1679, 'consider': 896, 'Tale': 512, 'Two': 549, 'Sisters': 472, 'greatest': 1292, 'bold': 744, 'depicts': 977, 'vessel': 2306, 'taken': 2137, 'mighty': 1583, 'frost': 1241, 'speak': 2045, 'indescribably': 1401, 'idiotic': 1378, 'bendingly': 727, 'poignant': 1752, 'FINALLY': 185, 'handled': 1309, 'competent': 878, 'Jerry': 296, 'Falwell': 189, 'walk': 2330, 'theatre': 2172, 'relief': 1869, 'starring': 2065, 'Jaclyn': 290, 'Smith': 475, 'god': 1276, '12': 1, 'documentaries': 1028, 'relationships': 1865, 'marriage': 1552, 'Now': 394, 'chosen': 843, 'tortured': 2207, 'disgusting': 1017, 'blatant': 738, 'American': 46, 'propaganda': 1803, 'superbly': 2116, 'acted': 609, 'Scream': 455, 'ranks': 1830, 'Victor': 560, 'McLaglen': 367, 'Brian': 91, 'DonLevy': 156, 'unrecognizable': 2283, 'Lovely': 345, 'thriller': 2187, 'Hitchcock': 263, 'shenanigans': 1986, 'surrounding': 2127, 'murdered': 1615, 'spy': 2057, 'kidnapped': 1453, 'nasty': 1622, 'church': 844, 'foreign': 1227, 'random': 1829, 'taxidermists': 2149, 'Thunderbirds': 527, 'Ursula': 556, 'Burton': 95, 'nun': 1651, 'touching': 2211, 'nuns': 1652, 'episodes': 1114, 'nut': 1653, 'bag': 705, 'note': 1648, 'Stephen': 492, 'McHattie': 366, 'Lance': 324, 'Hendrikson': 255, 'raging': 1828, 'cheekbones': 830, 'Enough': 173, 'remarkable': 1873, 'recommended': 1852, 'explosion': 1148, 'Gas': 220, 'tanks': 2145, 'nonetheless': 1643, 'act': 608, 'drift': 1052, 'earth': 1066, 'supposed': 2121, 'clever': 853, 'twist': 2239, 'light': 1498, 'situation': 2011, 'Feelings': 194, 'Gabriel': 217, 'discomfort': 1014, 'dance': 952, 'intangibles': 1416, 'leap': 1484, 'viewer': 2312, 'grasp': 1289, 'Nothing': 393, 'theater': 2171, 'wanting': 2335, 'Robert': 441, 'Ryans': 443, 'portrayed': 1765, 'father': 1180, 'schizophrenic': 1938, 'affected': 628, 'world': 2381, 'confusing': 894, 'subplots': 2102, 'native': 1625, 'americans': 644, 'brain': 761, 'eating': 1069, 'brainsucking': 762, 'case': 800, 'attractive': 686, 'set': 1972, 'eye': 1152, 'pleasing': 1747, 'Seriously': 460, 'wasting': 2345, 'kid': 1452, 'choked': 842, 'vomit': 2326, 'worthless': 2386, 'death': 958, 'Conclusion': 124, 'trying': 2231, 'rocked': 1907, 'social': 2030, 'physical': 1725, 'outlets': 1675, 'wants': 2336, 'surf': 2124, 'wave': 2350, '1998': 13, 'Deep': 145, 'Impact': 280, 'Armageddon': 57, 'phrase': 1724, 'conflict': 893, 'owed': 1684, 'pleased': 1745, 'genius': 1259, 'letting': 1492, 'passion': 1704, 'Art': 58, 'plenty': 1748, 'lines': 1506, 'cuts': 948, 'audio': 688, 'sibling': 1995, 'bond': 745, 'ended': 1096, 'disliked': 1019, 'despised': 989, 'high': 1338, 'adventure': 624, 'journey': 1443, 'touches': 2210, 'member': 1571, 'bland': 737, 'location': 1516, 'Funny': 215, 'hip': 1343, 'Pray': 428, 'previous': 1787, 'Hype': 276, 'youtube': 2407, 'happy': 1315, 'mean': 1563, 'distinction': 1021, 'Americans': 47, 'hatred': 1320, 'admitted': 622, 'shell': 1984, 'carries': 796, 'tickets': 2193, 'dollars': 1034, '50': 21, 'miss': 1592, 'potted': 1770, 'plants': 1737, 'excuse': 1134, 'Juano': 303, 'Hernandez': 258, 'supporting': 2120, 'era': 1116, 'proud': 1805, 'accused': 606, 'murdering': 1616, 'Why': 581, 'attempts': 684, 'humor': 1370, 'dosen': 1039, 'thinking': 2179, 'basically': 715, 'involves': 1430, 'Vulcan': 561, 'stealing': 2072, 'Enterprise': 174, 'oh': 1664, 'Uhura': 554, 'belly': 726, 'distract': 1023, 'guards': 1298, 'veteran': 2307, 'nostalgia': 1646, 'trip': 2225, 'magnificent': 1539, 'photography': 1723, 'frightening': 1240, 'comprehensible': 886, 'left': 1487, 'lilt': 1503, 'step': 2073, 'heart': 1325, 'race': 1825, 'Editing': 166, 'phenomenal': 1720, 'opinion': 1669, 'Interview': 284, 'With': 585, 'Vampire': 557, 'Lestat': 331, 'Stuart': 499, 'Townsend': 541, 'Cruise': 135, 'contract': 906, 'control': 908, 'scripts': 1948, 'forgot': 1231, 'Casting': 111, 'Trond': 544, 'Fausa': 192, 'Aurvåg': 63, 'Bothersome': 88, 'Man': 355, 'doing': 1033, 'longer': 1520, 'goes': 1277, 'surprised': 2125, 'paced': 1687, 'understated': 2259, 'courtroom': 923, 'smart': 2024, 'Aailiyah': 30, 'Akasha': 40, 'places': 1734, 'compelling': 877, 'entrance': 1112, 'mini': 1586, 'realized': 1844, 'closed': 859, 'brilliance': 768, 'friends': 1239, 'bipolarity': 733, 'ruthless': 1919, 'thug': 2191, 'killer': 1455, 'Luv': 348, 'diaper': 997, 'commercial': 875, 'unconvincing': 2251, 'Special': 485, 'score': 1940, 'integral': 1417, 'element': 1083, 'helping': 1333, 'cartoon': 798, 'Century': 112, 'ROAD': 435, 'HOUSE': 242, '1948': 7, 'silly': 2000, 'noir': 1641, 'implausible': 1385, 'unmitigated': 2275, 'exemplars': 1137, 'designer': 987, 'pleasant': 1744, 'voyage': 2327, 'discovery': 1016, 'wondered': 2371, 'shortlist': 1990, 'sweet': 2132, 'moments': 1598, 'captures': 792, 'essence': 1120, 'Almost': 43, 'Cover': 131, 'Girl': 227, 'fashioned': 1176, 'tuneful': 2234, 'sloppy': 2019, 'universe': 2272, 'excessively': 1132, 'phony': 1721, 'contrived': 907, 'sit': 2009, 'Maybe': 365, 'reasonable': 1847, 'explanation': 1146, 'atrocity': 682, 'commentary': 873, 'today': 2202, 'undoubtedly': 2262, 'Stewart': 493, 'hero': 1335, 'rips': 1904, 'climax': 857, 'embassy': 1086, 'function': 1245, 'brooding': 775, 'menace': 1576, 'Bela': 75, 'Lugosi': 347, 'extraneous': 1150, 'intoning': 1427, 'Go': 231, 'Garbo': 219, 'bat': 716, 'talents': 2143, 'carry': 797, 'silent': 1999, 'Netflix': 386, 'stocking': 2078, 'Perabo': 418, 'comfortable': 868, 'slightest': 2016, 'uniqueness': 2271, 'Ticker': 528, 'Estevez': 176, 'directorial': 1009, 'debut': 960, 'pacing': 1688, 'development': 993, 'plays': 1743, 'suggest': 2111, 'natural': 1626, 'tired': 2201, 'readers': 1837, 'worthwhile': 2387, 'Generally': 221, 'lacked': 1467, 'solid': 2032, 'added': 619, 'bonuses': 748, 'fat': 1179, 'computer': 888, 'geek': 1255, 'bible': 730, 'thumper': 2192, 'ass': 676, 'unfolds': 2265, '18th': 5, 'century': 811, 'Jutland': 308, 'instruments': 1413, 'touch': 2209, 'Excellently': 183, 'produced': 1793, 'Sci': 453, 'fi': 1195, 'producers': 1795, 'Scot': 454, 'Vandiver': 558, 'wont': 2374, 'hate': 1318, 'reviews': 1900, 'star': 2063, 'expect': 1139, 'remotely': 1876, 'sum': 2113, 'Breeders': 90, 'cheaply': 828, 'avoided': 692, 'Ebola': 164, 'virus': 2317, 'filmmaker': 1197, 'hide': 1337, 'sand': 1924, 'spent': 2049, 'extraordinary': 1151, 'accents': 602, 'abysmal': 601, 'Both': 87, 'credit': 936, '1986': 11, 'version': 2305, 'watchable': 2347, 'word': 2376, 'loosely': 1526, 'public': 1811, 'scale': 1930, 'balanced': 708, 'underacting': 2252, 'Aside': 61, 'debits': 959, 'Filmiing': 197, 'expansive': 1138, 'explain': 1144, 'romantic': 1913, 'junkyard': 1447, 'laughed': 1479, 'LOVE': 319, 'Cinematography': 118, 'stunning': 2094, 'Clever': 119, 'crowd': 939, 'pleaser': 1746, '80': 26, 'results': 1894, 'shame': 1977, 'riot': 1903, 'Hugo': 273, 'Weaving': 573, 'sex': 1976, 'obsessed': 1655, 'gay': 1254, 'estate': 1122, 'salesman': 1923, 'uses': 2292, 'clients': 856, 'houses': 1366, 'trysts': 2232, 'flaming': 1209, 'Darren': 141, 'Hollander': 265, 'Lot': 342, 'holes': 1349, 'emperor': 1090, 'spend': 2048, 'Trumbull': 547, 'LUCY': 320, 'rare': 1831, 'maker': 1544, 'worthy': 2388, 'moral': 1604, 'tale': 2140, 'trap': 2218, 'overly': 1680, 'syrupy': 2135, 'indulgent': 1404, 'won': 2369, 'fish': 1205, 'underwater': 2261, 'repeated': 1882, 'thousand': 2183, 'amusing': 645, 'exactly': 1127, 'latched': 1473, 'endearing': 1095, 'isn': 1433, 'achievement': 607, 'evaluate': 1123, 'lives': 1512, 'pair': 1695, 'fishnet': 1206, 'stockings': 2079, 'astonishingly': 678, 'ham': 1306, 'fisted': 1207, 'felt': 1191, 'Ireland': 285, 'End': 171, 'Days': 142, 'See': 459, 'chance': 815, 'open': 1667, 'Crowe': 134, 'dedication': 965, 'hands': 1311, 'par': 1699, 'Worst': 589, 'hour': 1363, 'half': 1304, 'gosh': 1284, 'wild': 2364, 'stuff': 2093, 'fans': 1169, 'SETS': 444, 'oy': 1685, 'vey': 2308, 'inside': 1406, 'emotions': 1089, 'Helen': 253, 'Baxendale': 72, 'credible': 935, 'lady': 1470, 'Macbeth': 353, 'cheerfull': 831, 'naughty': 1628, 'deadly': 957, 'taste': 2148, 'blood': 740, 'evil': 1125, 'skilled': 2013, 'Sandra': 448, 'Bullock': 94, 'Speed': 486, 'northern': 1645, 'positive': 1767, 'community': 876, 'represents': 1886, 'Easily': 162, 'tender': 2162, 'getting': 1264, 'dark': 954, 'sitcoms': 2010, 'oriented': 1671, 'teenagers': 2157, 'throwback': 2189, 'student': 2092, '1980': 10, 'experiences': 1143, 'living': 1513, 'abroad': 599, 'interacting': 1421, 'nationalities': 1624, 'circumstances': 848, 'slightly': 2017, 'Gerardo': 223, 'Characters': 114, 'dimensional': 1003, 'guys': 1303, 'Of': 397, '70s': 25, 'grainy': 1287, 'enhanced': 1102, 'quick': 1822, 'glance': 1273, 'Yeah': 592, 'sucked': 2108, 'Jennifer': 295, 'Rubin': 442, 'Jamie': 292, 'Harris': 247, 'changes': 817, 'nervous': 1635, 'starlet': 2064, 'strange': 2086, 'events': 1124, 'honest': 1352, 'foolish': 1223, 'pretext': 1785, 'NOTHING': 384, 'Non': 391, 'linear': 1505, 'narration': 1621, 'flashbacks': 1210, 'articulated': 667, 'doubt': 1040, 'motion': 1606, 'needlessly': 1632, 'repeats': 1884, 'backed': 702, 'continuity': 905, 'vehicles': 2301, 'Corn': 129, 'Flakes': 200, 'box': 759, 'bordered': 752, 'stupidity': 2096, 'Lewis': 333, 'Black': 83, 'considerable': 897, 'talent': 2141, 'incendiary': 1394, 'unrestrained': 2285, 'rating': 1834, 'allow': 640, 'My': 379, 'Beware': 80, 'trashy': 2220, 'indictment': 1403, 'justice': 1449, 'Well': 575, 'tolerate': 2204, 'political': 1758, 'incorrectness': 1398, 'artistic': 669, 'freedom': 1237, 'suspension': 2130, 'disbelief': 1013, 'Slavic': 473, 'female': 1192, 'dropped': 1056, 'ball': 709, 'Neil': 385, 'LaBute': 321, 'brutal': 776, 'violence': 2315, 'seperate': 1965, 'dreams': 1049, 'Ms': 376, 'Top': 539, 'face': 1153, 'writers': 2394, 'smack': 2022, 'bonus': 747, 'These': 521, 'Frankly': 208, 'Cotton': 130, 'club': 860, 'Unfaithful': 555, 'embarrassing': 1085, 'Gere': 224, 'Punishment': 430, 'Park': 414, 'sole': 2031, 'bright': 767, 'spot': 2056, 'Superbad': 502, 'weight': 2355, 'interim': 1424, 'powerful': 1772, 'explorations': 1147, 'casted': 802, 'jokes': 1442, 'offend': 1663, 'decay': 961, 'Shakespears': 463, 'lyrics': 1537, 'deeply': 966, 'impressed': 1388, 'Monica': 372, 'Bellucci': 76, 'sentiment': 1964, 'Her': 256, 'WRITTEN': 565, 'um': 2245, 'broke': 774, 'judging': 1445, 'fumbling': 1243, 'hankies': 1312, 'faces': 1154, 'males': 1549, 'females': 1193, 'alike': 639, 'ugly': 2243, 'crafted': 926, 'Haggis': 245, 'handle': 1308, 'strokes': 2088, 'storytelling': 2085, 'painted': 1694, 'crayons': 930, 'Dustin': 160, 'Hoffman': 264, 'son': 2035, 'flat': 1211, 'nearly': 1629, 'Simply': 471, 'unpleasant': 2279, 'pictures': 1728, 'flawed': 1213, 'core': 915, 'MANNA': 349, 'FROM': 187, 'HEAVEN': 241, 'ed': 1070, 'comments': 874, 'wall': 2332, 'uncalled': 2249, 'Regardless': 438, 'afraid': 629, 'subtitles': 2103, 'aversion': 690, 'therapy': 2175, 'disappointing': 1011, 'aspects': 675, 'lack': 1466, 'notable': 1647, 'gore': 1282, 'BORING': 67, 'card': 793, 'aside': 671, 'lets': 1491, 'major': 1542, 'flaw': 1212, 'destroy': 991, 'latifa': 1476, '25': 18, 'amazed': 642, 'timeless': 2196, 'simplifying': 2001, 'brevity': 765, 'fulfilling': 1242, 'Was': 568, 'Cool': 128, 'irritating': 1432, 'inspiring': 1410, 'proceedings': 1791, 'Damian': 140, 'versatile': 2304, 'portraying': 1766, 'impressive': 1389, 'Call': 104, 'Great': 236, 'Telly': 516, 'Savalas': 450, 'Peter': 420, 'Boyle': 89, '54': 22, 'sheer': 1982, 'tedium': 2155, 'melodrama': 1570, 'sinking': 2007, 'GOOD': 216, 'LORD': 318, 'WHAT': 564, 'WERE': 563, 'THEY': 507, 'THINKING': 508, 'Lots': 343, 'imagine': 1384, 'decisions': 964, 'atrocious': 681, 'stinks': 2077, 'Trouble': 546, 'impossible': 1387, 'establish': 1121, 'theme': 2174, 'Worse': 588, 'incredibly': 1400, 'follows': 1222, 'band': 710, 'Mansonites': 356, 'reporter': 1885, 'working': 2379, 'anniversary': 653, 'killings': 1457, 'dumb': 1060, 'spoil': 2052, 'indication': 1402, 'writer': 2393, 'ability': 598, 'meld': 1569, 'volatile': 2324, 'temperaments': 2161, 'seamless': 1951, 'union': 2270, 'creativity': 934, 'result': 1893, 'powerhouse': 1773, 'timely': 2197, 'culture': 942, 'disturbing': 1025, 'fascination': 1175, 'celebrity': 808, 'distorted': 1022, 'interpretations': 1426, 'fame': 1165, 'forgotten': 1232, 'Kevin': 312, 'Spacey': 484, 'verbal': 2302, 'tsunami': 2233, 'Buddy': 92, 'Ackerman': 34, 'scripting': 1947, 'unmatched': 2274, 'ages': 633, 'younger': 2405, 'references': 1856, 'galley': 1249, 'Also': 44, 'pm': 1750, '8pm': 27, '15pm': 4, 'forwarded': 1235, 'remaining': 1871, 'Either': 167, 'sucks': 2109, 'horrendously': 1357, 'starts': 2069, 'build': 778, 'Captain': 107, 'Howdy': 270, 'says': 1929, 'plain': 1735, 'semi': 1961, 'truck': 2227, 'Linda': 336, 'Cardellini': 108, 'poised': 1756, 'Dee': 144, 'Snider': 476, 'villains': 2314, 'write': 2392, 'damn': 951, 'FX': 188, 'suck': 2107, 'tries': 2223, 'sophisticated': 2038, 'miserably': 1591, 'unoriginal': 2278, 'cinematic': 846, 'captured': 791, 'celluloid': 809, 'stayed': 2071, 'supernatural': 2119, 'zombie': 2409, 'Season': 458, 'Five': 199, 'consistent': 899, 'thread': 2184, 'holding': 1347, 'Leni': 330, 'Parker': 415, 'Anita': 54, 'LaSelva': 322, 'Taelons': 511, 'quiet': 1823, 'idealogical': 1374, 'dislike': 1018, 'Horror': 268, 'mainly': 1541, 'centers': 810, 'atmosphere': 680, 'Puppet': 431, 'Master': 362, 'flicks': 1215, 'NEVER': 380, 'explains': 1145, 'sinister': 2006, 'origins': 1673, 'insomniacs': 1408, 'heartwarming': 1326, 'chasing': 826, 'Nurse': 395, 'Betty': 79, 'unpredictability': 2280, 'Kris': 316, 'Kristoffersen': 317, 'difference': 1000, 'sad': 1920, 'repeating': 1883, 'robotic': 1906, 'moves': 1611, 'convoluted': 913, 'convince': 911, 'questioning': 1821, 'Technically': 514, 'Riz': 440, 'Ortolani': 405, 'recurring': 1853, 'unaccompanied': 2246, 'vocal': 2322, 'sounds': 2042, 'distant': 1020, 'hill': 1342, 'arts': 670, 'poetry': 1751, 'politics': 1760, 'Japanese': 293, 'gloriously': 1274, 'fairly': 1160, 'accurate': 605, 'raver': 1835, 'players': 1741, 'mesmerising': 1580, 'Kathy': 309, 'Bates': 71, 'desperation': 988, 'escapism': 1118, 'variation': 2299, 'Play': 425, 'Fields': 196, 'Lord': 340, 'heard': 1324, 'gripping': 1295, 'theatrical': 2173, 'terror': 2170, 'lie': 1496, 'escalating': 1117, 'monstrous': 1603, 'consequences': 895, 'standout': 2062, 'Wow': 590, 'needed': 1631, 'mouth': 1608, 'promote': 1800, 'Jason': 294, 'Connery': 125, 'moved': 1609, 'tears': 2154, 'monolog': 1600, 'candle': 790, 'sphere': 2050, 'likes': 1502, 'uneasy': 2263, 'faultless': 1181, 'underappreciated': 2253, 'Keith': 311, 'bully': 782, 'Teddy': 515, 'vivid': 2321, 'failed': 1158, 'convey': 910, 'broad': 773, 'sweep': 2131, 'landscapes': 1472, 'Pitch': 423, 'Mouse': 374, 'following': 1221, 'PLANE': 409, 'CRAZY': 102, 'earlier': 1064, 'famous': 1167, 'ground': 1297, 'breaking': 764, 'warn': 2339, 'DO': 138, 'NOT': 383, 'RENT': 434, 'THIS': 509, 'MOVIE': 351, 'dumbest': 1061, 'renowned': 1879, 'Frances': 207, 'Marion': 359, 'hasn': 1317, 'realize': 1843, 'THERE': 506, 'IS': 278, 'NO': 381, 'PLOT': 410, 'OR': 396, 'STORYLINE': 446, 'Gotta': 234, 'slimy': 2018, 'drooling': 1055, 'teeth': 2158, 'Shakespear': 462, 'prompted': 1801, 'screamy': 1941, 'masculine': 1554, 'allowing': 641, '1971': 8, 'format': 1234, 'baaaaaad': 699, 'When': 579, 'Achille': 33, 'Philippa': 422, 'beautifully': 719, 'sing': 2003, 'Giovanni': 226, 'describes': 981, 'layers': 1480, 'idyllic': 1379, 'downs': 1041, 'remake': 1872, 'Friends': 211, 'Wedding': 574, 'Crash': 133, 'depressing': 978, 'provokes': 1807, 'emotion': 1088, 'teaches': 2151, 'prejudice': 1778, 'gifted': 1267, 'Jim': 297, 'Connor': 126, 'energetic': 1100, 'George': 222, 'gone': 1279}\n",
      "Vocabulary words:  dict_keys(['Give', 'look', 'In', 'fact', 'stinker', 'smells', 'like', 'direct', 'video', 'release', 'Every', 'single', 'character', 'hilarious', 'deserved', 'called', 'lead', 'This', 'movie', 'does', 'excellent', 'job', 'revealing', 'complexity', 'task', 'incredible', 'challenges', 'facing', 'South', 'Africa', 'problems', 'dont', 'know', 'start', 'Judith', 'Light', 'favorite', 'actresses', 'think', 'superb', 'film', 'joins', 'Revenge', 'Boogeyman', 'Zombiez', 'hellish', 'trinity', 'horror', 'films', 'You', 'relate', 'hell', 'barely', 'understand', 'The', 'boring', 'occupied', 'peaking', 'paper', 'instead', 'watching', 'happened', 'Columbo', 'stories', 'unbelievable', 'actors', 'Think', 'dream', 'Lassie', 'sleep', 'FOREVER', 'routine', 'based', 'TV', 'drama', 'gets', 'boost', 'fine', 'performance', 'Cole', 'It', 'right', 'balance', 'war', 'love', 'rate', '10', 'fun', 'funny', 'Hopefully', 'director', 'James', 'Cox', 'turn', 'short', 'feature', 'length', 'cast', 'win', 'new', 'Exceptionally', 'bad', 'practically', 'perfect', 'true', 'masterpiece', 'sea', 'faux', 'masterpieces', 'Tom', 'Wilkinson', 'man', 'prepared', 'ordeal', 'begin', 'takes', 'matter', 'hand', 'story', 'progresses', 'great', 'actor', 'gives', 'makes', 'feel', 'anguish', 'suffering', 'Highly', 'entertaining', 'angles', 'just', 'adorable', 'seeing', 'Mickey', 'playing', 'Turkey', 'Straw', 'highly', 'imaginative', 'occasionally', 'cruel', 'way', 'DELETE', 'mind', 'definitely', 'cult', 'classic', 'worth', 'viewing', 'sharing', 'music', 'really', 'nice', 'football', 'scenes', 'end', 'perplexing', 'Shot', 'Southern', 'California', 'desert', 'using', 'patent', 'documentary', 'style', 'Watkins', 'creates', 'Definitely', 'checking', 'Very', 'relaxing', 'late', 'night', 'Oh', 'yeah', 'storyline', 'pathetic', 'terribly', 'disappointed', 'receive', 'awards', 'accolades', 'especially', 'far', 'deserving', 'works', 'Totally', 'different', 'loads', 'understatement', 'black', 'comedy', 'remember', 'Even', 'women', 'finally', 'sign', 'improvement', 'expected', 'things', 'happen', 'time', 'asleep', 'All', 'make', 'sick', 'slackers', 'excuses', 'stupid', 'actions', '90', 'minutes', 'Personally', 'shows', 'people', 'learn', 'compromise', 'self', 'involving', 'issue', 'Considering', 'relations', 'screen', 'Taylor', 'Stanwyck', 'surprising', 'little', 'chemistry', 'll', 'Angel', 'beautiful', 'Scamp', 'His', 'yelps', 'hes', 'scared', 'funniest', 'parts', 'caught', 'curtain', 'singing', 'Ive', 'Never', 'Had', 'Feeling', 'Before', 'totally', 'recommend', 'coming', 'special', 'edition', 'June', '20', 'cover', 'scamp', 'garbage', 'underneath', 'lid', 'CG', 'opening', 'sequence', 'space', 'looked', 'created', 'Microsoft', 'Slideshow', 'God', 'sake', 'deserves', 'strong', 'kudos', 'taking', 'stand', 'having', 'exceptional', 'acting', 'lesser', 'known', 'super', 'intelligent', 'script', 'doesn', 'insult', 'audience', 'easy', 'comes', 'white', 'racism', 'came', 'free', 'DVD', 'player', 'bought', 'turned', 'thing', 'halfway', 'embarrassed', 'Howell', 'But', 'duet', 'astronaut', 'doctor', 'beginning', 'exchange', 'considers', 'Cold', 'War', 'biggest', 'fear', 'crashed', 'USSR', 'couldn', 'seriously', 'interplay', 'Martin', 'Emilio', 'contains', 'wonderful', 'saw', 'Wall', 'Street', 'Charlie', 'Avoid', 'costs', 'If', 'probably', 'leave', 'shelf', 'One', 'worst', 'For', 'awful', 'dialogue', 'hopeless', 'overacting', 'shot', 'real', 'waste', 'Despite', 'pans', 'reviewers', 'liked', 'Don', 'rubbish', 'non', 'researched', 'To', 'masterful', 'say', 'intelligence', 'imagination', 'obviously', 'used', 'try', 'sense', 'pitiful', 'attempt', 'human', 'nature', 'involved', 'includes', 'Shatner', 'Nimoy', 'washed', 'making', 'old', 'life', 'effects', 'tacky', 'Spock', 'rescue', 'Kirk', 'jet', 'pack', 'falls', 'mountain', 'walked', 'faster', 'HBO', 'day', 'absolutely', 'loved', 'Much', 'interesting', 'action', 'suspense', 'unneeded', 'controversy', 'littered', 'overt', 'racial', 'slurs', 'members', 'return', 'whites', 'depicted', 'morons', 'boobs', 'don', 'got', 'shelves', 'store', 'watch', 'long', 'losing', 'spoilers', 'huge', 'disappointment', 'painful', 'let', 'girlfriend', 'talk', 'idea', 'hated', 'From', 'Widmark', 'turns', 'unintentionally', 'comical', 'original', 'Body', 'Soul', '1947', 'aerial', 'NOBODY', 'identifies', 'characters', 'cardboard', 'cutouts', 'stereotypes', 'predictably', 'reverse', 'Everything', 'appalling', 'Really', 'scary', 'No', 'plot', 'whatsoever', 'paid', 'He', 'unbearable', 'charisma', 'terrible', 'comedic', 'timing', 'fantastic', 'seamlessly', 'woven', 'dogs', 'splendid', 'rent', 'view', 'ceases', 'simply', 'keeps', 'alert', 'decipher', 'meanings', 'exquisite', 'visual', 'composition', 'moment', 'inventive', 'elegant', 'use', 'close', 'camera', 'angle', 'lighting', 'including', 'pointillistic', 'home', 'footage', 'wonder', 'joy', 'behold', 'Christmas', 'showed', 'lot', 'Florida', 'best', 'appealing', 'Too', 'politically', 'correct', 'predictable', 'chick', 'flick', 'cutting', 'edge', 'Hated', 'How', 'piece', 'trash', 'released', 'supposedly', 'ALL', 'wrong', 'thought', 'awesome', 'Ebay', 'Julian', 'Fellowes', 'triumphed', 'advise', 'Elias', 'Koteas', 'Jack', 'Palance', 'play', 'good', 'roles', 'Angelina', 'hot', 'naked', 'Billy', 'Drago', 'appears', 'cool', 'usual', 'cameo', 'Sven', 'ole', 'Thorsen', 'helps', 'enjoyable', 'decent', 'budget', 'success', 'depends', 'casting', 'Sydney', 'Greenstreet', 'Alexander', 'Yardley', 'That', 'painfully', 'dreary', 'waster', 'IQ', 'particularly', 'mollusk', 'looks', 'rough', 'draft', 'written', 'shooting', 'began', 'finished', 'completed', 'child', '1973', 'Stranger', 'average', 'main', 'person', 'low', 'clearly', 'lacks', 'scares', 'tension', 'medical', 'terminology', 'bit', 'iffy', 'insulin', 'dependant', 'diabetic', 'wasn', 'expecting', 'Oscar', 'material', 'Instead', 'bore', 'fest', 'whiny', 'spoiled', 'brat', 'babysitting', 'sort', 'pap', 'screened', 'afternoon', 'punish', 'unemployed', 'jobs', 'Omit', 'Director', 'Paul', 'Matthews', 'wrote', 'directed', 'weak', '1995', 'monster', 'Grim', 'pace', 'hope', 'team', 'movies', 'continue', 'kinda', 'weird', 'peculiarity', 'Loved', 'Jimmy', 'Buffet', 'science', 'teacher', 'believe', 'screenwriter', 'did', 'tying', 'loose', 'ends', 'Overall', 'provoking', 'Only', 'buildings', 'couple', 'locations', 'MAYBE', 'poor', 'hummh', 'They', 'identify', 'need', 'memorized', 'She', 'lovely', 'cutie', 'memories', 'murky', 'enjoyed', 'episode', 'product', 'related', 'struggle', 'timers', 'Predictable', 'Again', 'Errol', 'Flynn', 'brilliant', 'dads', 'favourite', 'grew', 'scenery', 'daughters', 'paint', 'photograph', 'forces', 'question', 'threshold', 'loneliness', 'portrayal', 'family', 'share', 'ups', 'knew', 'literally', 'excerpts', 'Star', 'Trek', 'final', 'Frontier', 'series', 'drive', 'barking', 'mad', 'guess', 'network', 'aired', 'dribble', 'watched', 'putting', 'Being', 'truly', 'proudly', 'big', 'classical', 'WB', 'cartoons', 'composed', 'However', 'didn', 'overall', 'tremendously', 'delight', 'After', 'wanted', 'artist', 'cheap', 'cheerless', 'heist', 'characterisation', 'lots', 'underbite', 'stoic', 'emoting', 'Chow', 'Yun', 'Fat', 'Better', 'Tomorrow', 'cheesy', 'clichés', 'thrown', 'abandoned', 'factory', 'ready', 'poorly', 'executed', 'flying', 'judo', 'rolls', 'la', 'John', 'Woo', 'setting', 'possible', 'redeemed', 'MST3K', 'fodder', 'year', 'reminded', 'Huston', 'game', 'evinced', 'faithful', 'adaptation', 'Joyce', 'acclaimed', 'novella', 'Dead', 'premise', 'sound', 'Lange', 'actress', 'Lifetime', 'air', 'knows', 'sells', 'soundtrack', 'slow', 'moving', 'aimless', 'distressed', 'drifting', 'young', 'Fans', 'genre', 'heaven', 'steve', 'martin', 'delivers', 'middle', 'aged', 'upper', 'class', 'uptight', 'guy', 'sorry', 'What', 'volcano', 'Los', 'Angeles', 'About', '30', 'wasted', 'mediocre', 'elderly', 'awkwardly', 'babbling', 'overwrought', 'pseudo', 'Satanic', 'gibberish', 'corny', 'teen', 'Goth', 'blush', 'Olde', 'English', 'Latin', 'words', 'Foreigner', 'second', 'wish', 'enter', 'negative', 'values', 'admins', 'miserable', 'hollow', 'laughable', 'want', 'hosting', 'voice', 'overs', 'monotonous', 'guests', 'derivative', 'ending', 'mercy', 'killing', 'kind', 'idiot', 'produce', 'mess', 'place', 'mention', 'season', 'Lame', 'telephone', 'repair', 'reactions', 'nuts', 'bitchy', 'boss', 'genuine', 'said', 'better', 'situations', 'played', 'coach', 'fascinating', 'Paolo', 'Sorrentino', 'Tony', 'built', 'unforgettable', 'seen', 'recent', 'years', 'Plus', 'modest', 'fast', 'running', 'amazing', 'Whatever', 'producer', 'going', 'missed', 'entirely', 'transfers', 'started', 'thoughts', 'convincing', 'Lane', 've', 'lousy', 'recently', 'Fox', 'Movie', 'Channel', 'Having', 'humour', 'apt', 'money', 'Mark', 'Evil', 'Phantasm', 'discovering', 'falling', '40', 'line', 'Still', 'empowerment', 'Hayao', 'Miyazaki', 'latest', 'eighth', 'Studio', 'Ghibili', 'Gake', 'Ue', 'Ponyo', 'Cliff', 'Sea', 'wonderfully', 'childhood', 'Then', 'Sundays', 'ago', 'March', '20th', '2005', 'enjoy', 'taped', 'entire', 'bring', 'pillow', 'boyfriend', 'mature', 'subtle', 'suggests', 'brings', 'dramatic', 'focus', 'underlying', 'tensions', 'served', 'performances', 'apart', 'odd', 'inappropriate', 'smiling', 'Keira', 'Knightley', 'prone', 'direction', 'Not', 'elaborately', 'aesthetically', 'sculpture', 'unconditional', 'Tiny', 'Toons', 'kept', 'vibe', 'delivered', 'popular', 'underrated', 'poler', 'bear', 'cute', 'Fort', 'Steele', 'ask', 'away', 'Duris', 'wholesome', 'appearance', 'ultra', 'terrific', 'art', 'crayon', 'pencil', 'drawings', 'colorful', 'fanciful', 'SO', 'shed', 'tear', 'thrilled', 'forget', 'CLASSIC', 'Which', 'depth', 'Malta', 'settings', 'dry', 'barren', 'hockey', 'defensemen', 'goalies', 'diving', 'shots', 'feet', 'wide', 'net', 'haven', 'ridiculous', 'Started', 'particular', 'relationship', 'bakery', 'assistant', 'waitress', 'work', 'superficial', 'gave', 'feeling', 'stagey', 'stage', 'farce', 'By', 'pyromaniac', 'waylaid', 'bored', 'care', 'switched', 'Glad', 'pay', 'Didn', 'laugh', 'smile', 'yawn', 'educational', 'children', 'Barney', 'DE', 'duper', 'pretty', 'Babie', 'Bop', 'kids', 'Storm', 'Trooper', 'list', 'unrecommended', 'Just', 'avoid', 'Groove', 'antithesis', 'Human', 'Traffic', 'fails', 'create', 'sets', 'designed', 'stylized', 'effective', 'Schrader', 'Mishima', 'complex', 'conclusion', 'bother', 'nonsense', 'Anyway', 'flowed', 'smoothly', 'male', 'bonding', 'hoot', 'Final', 'Word', 'Show', 'torture', 'People', 'European', 'So', 'enjoyment', 'run', 'games', 'dangerous', 'Raw', 'sublimely', 'features', 'outlandish', 'array', 'memorable', 'psychotic', 'lovable', 'witty', 'delightful', 'Dr', 'Seuss', 'book', 'brilliantly', 'animated', 'UPA', 'finest', 'thoroughly', 'Academy', 'Award', 'horrible', 'cause', 'BAD', 'Actors', 'period', 'structure', 'easily', 'tightly', 'constructed', 'history', 'cinema', 'vitally', 'important', 'occurs', 'minute', 'content', 'level', 'dozen', 'quite', 'highest', 'superlative', 'form', 'imaginable', 'Yes', 'require', 'significant', 'puzzle', 'solving', 'pieces', 'fit', 'picture', 'certainly', 'pulls', 'punches', 'Graphics', 'number', 'TH', 'insane', 'There', 'massive', 'levels', 'unlockable', 'Waste', 'properly', 'Actually', 'graphics', 'Today', 'crap', 'As', 'Canada', 'aye', 'rocks', 'Buy', 'PURE', 'BRILLIANCE', 'doomed', 'conception', 'lame', 'minor', 'PG', '13', 'complete', 'sequel', 'changing', 'tone', 'rated', 'interested', 'confirm', 'unfunny', 'generic', 'managed', 'ENTIRE', 'exaggerating', 'point', 'joke', 'told', 'trailer', 'talented', 'Carrell', 'save', 'stars', 'fare', 'Morgan', 'Freeman', 'Jonah', 'Hill', 'Ed', 'Helms', 'lazy', 'presence', 'animals', 'integration', 'obvious', 'blue', 'green', 'cost', 'translate', 'quality', 'sure', 'succeeds', 'despite', 'meagre', 'glad', 'choice', 'addition', 'songs', 'French', 'Cancan', 'boasts', 'cutest', 'leading', 'ladies', 'grace', 'hard', 'fall', 'head', 'heels', 'girl', 'On', 'insipid', 'regret', 'hours', 'Long', 'pointless', 'waiting', 'future', 'efforts', 'Excellent', 'believable', 'Anne', 'Heche', 'utterly', 'Sam', 'Shepard', 'gung', 'ho', 'Marine', 'sobering', 'sat', 'riveted', 'resounding', 'Hanks', 'reading', 'annoying', 'fingernails', 'chalkboard', 'unnecessary', 'train', 'roller', 'coaster', 'scene', 'warmth', 'charm', 'grates', 'nerves', 'improved', 'improvisation', 'twice', 'worry', 'delivering', 'And', 'honestly', 'Often', 'follow', 'surroundings', 'crackles', 'unpredictable', 'youthful', 'energy', 'concentrate', 'meanders', 'badly', 'generally', 'wouldn', 'builders', 'cross', 'cliche', 'choices', 'parents', 'predict', 'dialog', 'verbatim', 'writing', 'selections', 'gross', 'chills', 'Nevsky', 'lived', 'pretentious', 'planned', 'Dodge', 'stratus', 'Big', 'Shots', 'gonna', 'help', 'makers', 'aren', 'restrained', 'business', 'Québec', 'jerky', 'movements', 'Things', 'personalities', 'change', 'twists', 'occur', 'reason', 'calls', 'Matrix', 'sequels', 'appreciate', 'mindblowing', 'experience', 'Songs', 'Were', 'Best', 'Muppets', 'Hilarious', 'rest', 'early', 'goremeister', 'Lucio', 'Fulci', 'giallo', 'sub', 'weren', 'forgetting', 'looking', 'Shirley', 'Jones', 'rendition', 'Way', 'Look', 'Tonight', 'uplifting', 'charismatic', '15', 'humorous', 'comment', '2006', 'Angus', 'Scrimm', 'somewhat', 'brief', 'role', 'gently', 'menacing', 'violin', 'anatomist', 'Doctor', 'Quinn', 'squibs', 'fresh', 'sublime', 'effect', 'shameful', 'handles', 'tough', 'issues', 'dignity', 'course', 'shocking', 'spoiler', 'wouldnt', 'redeeming', 'realised', 'actually', 'Let', 'professor', 'An', 'instant', 'catchy', 'song', 'credits', 'Some', 'applause', 'given', 'prelude', 'perfectly', 'ways', 'modern', 'equivalent', 'Dickens', 'Carol', 'sensibility', 'blew', 'Hackneyed', 'worse', 'directing', 'gem', 'terms', 'screenplay', 'cinematography', 'post', 'production', 'editing', 'aspect', 'national', 'treasure', 'zillion', 'times', 'reality', 'camp', 'value', 'inspiration', 'come', 'overcome', 'rejection', 'Italian', 'thrillers', '70', 'At', 'animation', 'dominated', 'Disney', 'Pixar', 'CGI', 'refreshing', 'comforting', 'relying', 'traditional', 'drawn', 'tell', 'charming', 'enchanting', 'Here', 'Wind', 'Lion', 'rendering', 'America', 'Imperial', 'age', 'Artless', 'endlessly', 'presents', 'ugliest', 'holds', 'attention', 'Emily', 'Watson', 'Horrible', 'UNfunny', 'unrealistic', 'utter', '70000', 'Later', 'lost', 'power', 'entertained', 'details', 'dysfunction', 'dull', 'uninteresting', 'forgettable', 'secondary', 'incomprehensible', 'relation', 'primary', 'mystifying', 'wooden', 'puppets', 'picked', 'speed', 'meaning', 'emptiness', 'house', 'small', 'consolations', 'sisters', 'completely', 'Titta', 'Di', 'Girolamo', 'stay', 'vision', 'horrified', 'sympathetic', 'review', 'overdue', 'consider', 'Tale', 'Two', 'Sisters', 'greatest', 'bold', 'depicts', 'vessel', 'taken', 'mighty', 'frost', 'speak', 'indescribably', 'idiotic', 'bendingly', 'poignant', 'FINALLY', 'handled', 'competent', 'Jerry', 'Falwell', 'walk', 'theatre', 'relief', 'starring', 'Jaclyn', 'Smith', 'god', '12', 'documentaries', 'relationships', 'marriage', 'Now', 'chosen', 'tortured', 'disgusting', 'blatant', 'American', 'propaganda', 'superbly', 'acted', 'Scream', 'ranks', 'Victor', 'McLaglen', 'Brian', 'DonLevy', 'unrecognizable', 'Lovely', 'thriller', 'Hitchcock', 'shenanigans', 'surrounding', 'murdered', 'spy', 'kidnapped', 'nasty', 'church', 'foreign', 'random', 'taxidermists', 'Thunderbirds', 'Ursula', 'Burton', 'nun', 'touching', 'nuns', 'episodes', 'nut', 'bag', 'note', 'Stephen', 'McHattie', 'Lance', 'Hendrikson', 'raging', 'cheekbones', 'Enough', 'remarkable', 'recommended', 'explosion', 'Gas', 'tanks', 'nonetheless', 'act', 'drift', 'earth', 'supposed', 'clever', 'twist', 'light', 'situation', 'Feelings', 'Gabriel', 'discomfort', 'dance', 'intangibles', 'leap', 'viewer', 'grasp', 'Nothing', 'theater', 'wanting', 'Robert', 'Ryans', 'portrayed', 'father', 'schizophrenic', 'affected', 'world', 'confusing', 'subplots', 'native', 'americans', 'brain', 'eating', 'brainsucking', 'case', 'attractive', 'set', 'eye', 'pleasing', 'Seriously', 'wasting', 'kid', 'choked', 'vomit', 'worthless', 'death', 'Conclusion', 'trying', 'rocked', 'social', 'physical', 'outlets', 'wants', 'surf', 'wave', '1998', 'Deep', 'Impact', 'Armageddon', 'phrase', 'conflict', 'owed', 'pleased', 'genius', 'letting', 'passion', 'Art', 'plenty', 'lines', 'cuts', 'audio', 'sibling', 'bond', 'ended', 'disliked', 'despised', 'high', 'adventure', 'journey', 'touches', 'member', 'bland', 'location', 'Funny', 'hip', 'Pray', 'previous', 'Hype', 'youtube', 'happy', 'mean', 'distinction', 'Americans', 'hatred', 'admitted', 'shell', 'carries', 'tickets', 'dollars', '50', 'miss', 'potted', 'plants', 'excuse', 'Juano', 'Hernandez', 'supporting', 'era', 'proud', 'accused', 'murdering', 'Why', 'attempts', 'humor', 'dosen', 'thinking', 'basically', 'involves', 'Vulcan', 'stealing', 'Enterprise', 'oh', 'Uhura', 'belly', 'distract', 'guards', 'veteran', 'nostalgia', 'trip', 'magnificent', 'photography', 'frightening', 'comprehensible', 'left', 'lilt', 'step', 'heart', 'race', 'Editing', 'phenomenal', 'opinion', 'Interview', 'With', 'Vampire', 'Lestat', 'Stuart', 'Townsend', 'Cruise', 'contract', 'control', 'scripts', 'forgot', 'Casting', 'Trond', 'Fausa', 'Aurvåg', 'Bothersome', 'Man', 'doing', 'longer', 'goes', 'surprised', 'paced', 'understated', 'courtroom', 'smart', 'Aailiyah', 'Akasha', 'places', 'compelling', 'entrance', 'mini', 'realized', 'closed', 'brilliance', 'friends', 'bipolarity', 'ruthless', 'thug', 'killer', 'Luv', 'diaper', 'commercial', 'unconvincing', 'Special', 'score', 'integral', 'element', 'helping', 'cartoon', 'Century', 'ROAD', 'HOUSE', '1948', 'silly', 'noir', 'implausible', 'unmitigated', 'exemplars', 'designer', 'pleasant', 'voyage', 'discovery', 'wondered', 'shortlist', 'sweet', 'moments', 'captures', 'essence', 'Almost', 'Cover', 'Girl', 'fashioned', 'tuneful', 'sloppy', 'universe', 'excessively', 'phony', 'contrived', 'sit', 'Maybe', 'reasonable', 'explanation', 'atrocity', 'commentary', 'today', 'undoubtedly', 'Stewart', 'hero', 'rips', 'climax', 'embassy', 'function', 'brooding', 'menace', 'Bela', 'Lugosi', 'extraneous', 'intoning', 'Go', 'Garbo', 'bat', 'talents', 'carry', 'silent', 'Netflix', 'stocking', 'Perabo', 'comfortable', 'slightest', 'uniqueness', 'Ticker', 'Estevez', 'directorial', 'debut', 'pacing', 'development', 'plays', 'suggest', 'natural', 'tired', 'readers', 'worthwhile', 'Generally', 'lacked', 'solid', 'added', 'bonuses', 'fat', 'computer', 'geek', 'bible', 'thumper', 'ass', 'unfolds', '18th', 'century', 'Jutland', 'instruments', 'touch', 'Excellently', 'produced', 'Sci', 'fi', 'producers', 'Scot', 'Vandiver', 'wont', 'hate', 'reviews', 'star', 'expect', 'remotely', 'sum', 'Breeders', 'cheaply', 'avoided', 'Ebola', 'virus', 'filmmaker', 'hide', 'sand', 'spent', 'extraordinary', 'accents', 'abysmal', 'Both', 'credit', '1986', 'version', 'watchable', 'word', 'loosely', 'public', 'scale', 'balanced', 'underacting', 'Aside', 'debits', 'Filmiing', 'expansive', 'explain', 'romantic', 'junkyard', 'laughed', 'LOVE', 'Cinematography', 'stunning', 'Clever', 'crowd', 'pleaser', '80', 'results', 'shame', 'riot', 'Hugo', 'Weaving', 'sex', 'obsessed', 'gay', 'estate', 'salesman', 'uses', 'clients', 'houses', 'trysts', 'flaming', 'Darren', 'Hollander', 'Lot', 'holes', 'emperor', 'spend', 'Trumbull', 'LUCY', 'rare', 'maker', 'worthy', 'moral', 'tale', 'trap', 'overly', 'syrupy', 'indulgent', 'won', 'fish', 'underwater', 'repeated', 'thousand', 'amusing', 'exactly', 'latched', 'endearing', 'isn', 'achievement', 'evaluate', 'lives', 'pair', 'fishnet', 'stockings', 'astonishingly', 'ham', 'fisted', 'felt', 'Ireland', 'End', 'Days', 'See', 'chance', 'open', 'Crowe', 'dedication', 'hands', 'par', 'Worst', 'hour', 'half', 'gosh', 'wild', 'stuff', 'fans', 'SETS', 'oy', 'vey', 'inside', 'emotions', 'Helen', 'Baxendale', 'credible', 'lady', 'Macbeth', 'cheerfull', 'naughty', 'deadly', 'taste', 'blood', 'evil', 'skilled', 'Sandra', 'Bullock', 'Speed', 'northern', 'positive', 'community', 'represents', 'Easily', 'tender', 'getting', 'dark', 'sitcoms', 'oriented', 'teenagers', 'throwback', 'student', '1980', 'experiences', 'living', 'abroad', 'interacting', 'nationalities', 'circumstances', 'slightly', 'Gerardo', 'Characters', 'dimensional', 'guys', 'Of', '70s', 'grainy', 'enhanced', 'quick', 'glance', 'Yeah', 'sucked', 'Jennifer', 'Rubin', 'Jamie', 'Harris', 'changes', 'nervous', 'starlet', 'strange', 'events', 'honest', 'foolish', 'pretext', 'NOTHING', 'Non', 'linear', 'narration', 'flashbacks', 'articulated', 'doubt', 'motion', 'needlessly', 'repeats', 'backed', 'continuity', 'vehicles', 'Corn', 'Flakes', 'box', 'bordered', 'stupidity', 'Lewis', 'Black', 'considerable', 'talent', 'incendiary', 'unrestrained', 'rating', 'allow', 'My', 'Beware', 'trashy', 'indictment', 'justice', 'Well', 'tolerate', 'political', 'incorrectness', 'artistic', 'freedom', 'suspension', 'disbelief', 'Slavic', 'female', 'dropped', 'ball', 'Neil', 'LaBute', 'brutal', 'violence', 'seperate', 'dreams', 'Ms', 'Top', 'face', 'writers', 'smack', 'bonus', 'These', 'Frankly', 'Cotton', 'club', 'Unfaithful', 'embarrassing', 'Gere', 'Punishment', 'Park', 'sole', 'bright', 'spot', 'Superbad', 'weight', 'interim', 'powerful', 'explorations', 'casted', 'jokes', 'offend', 'decay', 'Shakespears', 'lyrics', 'deeply', 'impressed', 'Monica', 'Bellucci', 'sentiment', 'Her', 'WRITTEN', 'um', 'broke', 'judging', 'fumbling', 'hankies', 'faces', 'males', 'females', 'alike', 'ugly', 'crafted', 'Haggis', 'handle', 'strokes', 'storytelling', 'painted', 'crayons', 'Dustin', 'Hoffman', 'son', 'flat', 'nearly', 'Simply', 'unpleasant', 'pictures', 'flawed', 'core', 'MANNA', 'FROM', 'HEAVEN', 'ed', 'comments', 'wall', 'uncalled', 'Regardless', 'afraid', 'subtitles', 'aversion', 'therapy', 'disappointing', 'aspects', 'lack', 'notable', 'gore', 'BORING', 'card', 'aside', 'lets', 'major', 'flaw', 'destroy', 'latifa', '25', 'amazed', 'timeless', 'simplifying', 'brevity', 'fulfilling', 'Was', 'Cool', 'irritating', 'inspiring', 'proceedings', 'Damian', 'versatile', 'portraying', 'impressive', 'Call', 'Great', 'Telly', 'Savalas', 'Peter', 'Boyle', '54', 'sheer', 'tedium', 'melodrama', 'sinking', 'GOOD', 'LORD', 'WHAT', 'WERE', 'THEY', 'THINKING', 'Lots', 'imagine', 'decisions', 'atrocious', 'stinks', 'Trouble', 'impossible', 'establish', 'theme', 'Worse', 'incredibly', 'follows', 'band', 'Mansonites', 'reporter', 'working', 'anniversary', 'killings', 'dumb', 'spoil', 'indication', 'writer', 'ability', 'meld', 'volatile', 'temperaments', 'seamless', 'union', 'creativity', 'result', 'powerhouse', 'timely', 'culture', 'disturbing', 'fascination', 'celebrity', 'distorted', 'interpretations', 'fame', 'forgotten', 'Kevin', 'Spacey', 'verbal', 'tsunami', 'Buddy', 'Ackerman', 'scripting', 'unmatched', 'ages', 'younger', 'references', 'galley', 'Also', 'pm', '8pm', '15pm', 'forwarded', 'remaining', 'Either', 'sucks', 'horrendously', 'starts', 'build', 'Captain', 'Howdy', 'says', 'plain', 'semi', 'truck', 'Linda', 'Cardellini', 'poised', 'Dee', 'Snider', 'villains', 'write', 'damn', 'FX', 'suck', 'tries', 'sophisticated', 'miserably', 'unoriginal', 'cinematic', 'captured', 'celluloid', 'stayed', 'supernatural', 'zombie', 'Season', 'Five', 'consistent', 'thread', 'holding', 'Leni', 'Parker', 'Anita', 'LaSelva', 'Taelons', 'quiet', 'idealogical', 'dislike', 'Horror', 'mainly', 'centers', 'atmosphere', 'Puppet', 'Master', 'flicks', 'NEVER', 'explains', 'sinister', 'origins', 'insomniacs', 'heartwarming', 'chasing', 'Nurse', 'Betty', 'unpredictability', 'Kris', 'Kristoffersen', 'difference', 'sad', 'repeating', 'robotic', 'moves', 'convoluted', 'convince', 'questioning', 'Technically', 'Riz', 'Ortolani', 'recurring', 'unaccompanied', 'vocal', 'sounds', 'distant', 'hill', 'arts', 'poetry', 'politics', 'Japanese', 'gloriously', 'fairly', 'accurate', 'raver', 'players', 'mesmerising', 'Kathy', 'Bates', 'desperation', 'escapism', 'variation', 'Play', 'Fields', 'Lord', 'heard', 'gripping', 'theatrical', 'terror', 'lie', 'escalating', 'monstrous', 'consequences', 'standout', 'Wow', 'needed', 'mouth', 'promote', 'Jason', 'Connery', 'moved', 'tears', 'monolog', 'candle', 'sphere', 'likes', 'uneasy', 'faultless', 'underappreciated', 'Keith', 'bully', 'Teddy', 'vivid', 'failed', 'convey', 'broad', 'sweep', 'landscapes', 'Pitch', 'Mouse', 'following', 'PLANE', 'CRAZY', 'earlier', 'famous', 'ground', 'breaking', 'warn', 'DO', 'NOT', 'RENT', 'THIS', 'MOVIE', 'dumbest', 'renowned', 'Frances', 'Marion', 'hasn', 'realize', 'THERE', 'IS', 'NO', 'PLOT', 'OR', 'STORYLINE', 'Gotta', 'slimy', 'drooling', 'teeth', 'Shakespear', 'prompted', 'screamy', 'masculine', 'allowing', '1971', 'format', 'baaaaaad', 'When', 'Achille', 'Philippa', 'beautifully', 'sing', 'Giovanni', 'describes', 'layers', 'idyllic', 'downs', 'remake', 'Friends', 'Wedding', 'Crash', 'depressing', 'provokes', 'emotion', 'teaches', 'prejudice', 'gifted', 'Jim', 'Connor', 'energetic', 'George', 'gone'])\n",
      "Vocabulary index:  dict_values([229, 1521, 282, 1156, 2076, 2025, 1500, 1004, 2310, 1867, 179, 2005, 819, 1341, 983, 784, 1482, 525, 1612, 1030, 1129, 1438, 1896, 883, 2147, 1399, 814, 1155, 482, 37, 1790, 1037, 1461, 2067, 304, 335, 1183, 616, 2178, 2115, 1196, 1440, 439, 85, 596, 1331, 2224, 1360, 1198, 594, 1860, 1330, 711, 2258, 518, 755, 1659, 1708, 1698, 1412, 2349, 1314, 123, 2082, 2248, 614, 524, 1048, 327, 2015, 186, 1915, 714, 510, 1044, 1263, 751, 1201, 1714, 122, 286, 1902, 707, 2337, 1533, 1832, 0, 1244, 1247, 266, 1008, 291, 132, 2235, 1989, 1186, 1488, 801, 2365, 1638, 184, 703, 1774, 1712, 2228, 1557, 1950, 1182, 1558, 533, 583, 1550, 1781, 1670, 721, 2138, 1560, 1307, 2083, 1799, 1291, 613, 1271, 1546, 1188, 649, 2110, 259, 1109, 648, 1448, 623, 1956, 368, 1742, 548, 497, 1340, 1383, 1658, 940, 2351, 137, 1584, 968, 941, 850, 2385, 2313, 1980, 1618, 1845, 1639, 1225, 1937, 1094, 1717, 468, 483, 103, 982, 2293, 1705, 1029, 2097, 570, 933, 146, 829, 559, 1866, 1474, 1640, 399, 2400, 2084, 1706, 2168, 1010, 1848, 693, 604, 1119, 1171, 985, 2380, 540, 1001, 1515, 2260, 736, 866, 1874, 178, 2368, 1200, 1997, 1391, 1140, 2177, 1313, 2195, 673, 42, 1543, 1996, 2014, 1135, 2095, 612, 28, 1589, 419, 1994, 1711, 1485, 887, 1959, 1431, 1434, 127, 1863, 1942, 513, 488, 2126, 1510, 834, 1514, 50, 718, 451, 262, 2403, 1336, 1932, 1246, 1703, 805, 943, 2004, 288, 387, 244, 193, 73, 2208, 1851, 871, 2046, 1073, 306, 14, 924, 1931, 1252, 2256, 1495, 99, 1668, 1968, 2044, 1522, 932, 369, 474, 232, 1922, 984, 2089, 1464, 2139, 2061, 1322, 1130, 610, 1489, 1462, 2114, 1420, 1946, 1031, 1415, 687, 1068, 867, 2360, 1827, 786, 1236, 139, 1740, 758, 2236, 2176, 1305, 1084, 271, 96, 1058, 679, 1027, 722, 1133, 898, 121, 567, 732, 1185, 928, 552, 920, 1970, 1425, 361, 169, 902, 2372, 1927, 566, 498, 115, 64, 919, 279, 1789, 1486, 1983, 403, 2384, 203, 696, 996, 1356, 1676, 1991, 1840, 2342, 147, 1696, 1899, 1501, 155, 1916, 1642, 1889, 531, 1556, 1928, 1419, 1382, 1657, 2291, 2230, 1962, 1732, 683, 1368, 1627, 1429, 1395, 464, 389, 2340, 1547, 1665, 1497, 1077, 2136, 487, 1888, 313, 1437, 1689, 1164, 1607, 2331, 1178, 240, 956, 600, 1534, 377, 1423, 611, 2129, 2277, 909, 1509, 1682, 1826, 2021, 1572, 1895, 2361, 976, 1605, 749, 1036, 1285, 1985, 2081, 2346, 1519, 1527, 2055, 1367, 1012, 1691, 1490, 1269, 2144, 1373, 1319, 212, 582, 2237, 2268, 870, 1672, 84, 481, 6, 626, 382, 1375, 821, 794, 947, 2074, 1777, 1897, 180, 657, 437, 1934, 390, 1749, 2358, 1690, 251, 2247, 822, 2167, 865, 2200, 1170, 1952, 2391, 1032, 2051, 1880, 2311, 807, 2002, 1450, 638, 963, 1566, 1149, 2319, 885, 1597, 1428, 1082, 2290, 858, 788, 647, 1499, 1396, 1754, 1351, 1224, 2370, 1444, 723, 117, 1993, 1529, 201, 728, 658, 537, 1759, 917, 1776, 835, 1214, 949, 1071, 248, 269, 1729, 2219, 1868, 2122, 29, 2397, 2181, 695, 163, 305, 195, 2226, 625, 168, 315, 289, 412, 1738, 1281, 1910, 52, 1362, 1620, 82, 158, 660, 914, 2294, 787, 503, 1666, 526, 1334, 1104, 962, 777, 2106, 975, 803, 504, 237, 41, 591, 517, 1692, 1050, 2344, 277, 1702, 1596, 1524, 1914, 1043, 2396, 1988, 720, 1204, 880, 836, 9, 496, 689, 1540, 1718, 1536, 852, 1468, 1933, 2163, 1567, 2165, 734, 1380, 1414, 974, 994, 2341, 1141, 406, 1559, 283, 753, 1194, 2359, 2053, 763, 701, 2040, 1697, 1943, 630, 1814, 2264, 1439, 401, 151, 416, 364, 2398, 1005, 2354, 12, 1602, 238, 1686, 1355, 2152, 1613, 904, 1459, 2356, 1709, 344, 298, 93, 1939, 2150, 725, 1945, 998, 2241, 1525, 1099, 407, 1808, 404, 780, 921, 1517, 350, 1761, 1369, 522, 1376, 1630, 1575, 465, 1535, 946, 1574, 1617, 1105, 1113, 1796, 1861, 2091, 2198, 429, 39, 175, 202, 769, 950, 1184, 1294, 1936, 955, 1693, 1722, 1226, 1820, 2185, 1518, 1764, 1166, 1979, 2288, 1460, 1508, 1131, 489, 543, 1199, 213, 1969, 1054, 712, 1538, 1299, 1637, 637, 1051, 2348, 1816, 74, 2229, 1806, 731, 851, 562, 799, 884, 272, 999, 1677, 2222, 969, 38, 2334, 668, 827, 832, 1329, 820, 1530, 2254, 2080, 1087, 116, 595, 191, 78, 534, 833, 855, 2190, 597, 1157, 1839, 1762, 1136, 1217, 1446, 1912, 1465, 299, 586, 1974, 1768, 1854, 352, 1219, 2401, 1875, 275, 1250, 1126, 1161, 618, 302, 603, 1649, 143, 1780, 2041, 326, 615, 334, 636, 1463, 1960, 2043, 2020, 1614, 635, 1024, 1053, 2404, 190, 1260, 1327, 2075, 1553, 973, 1582, 632, 2287, 849, 2289, 1302, 2039, 577, 2325, 341, 51, 31, 19, 2343, 1568, 1081, 697, 700, 1683, 1809, 449, 1266, 916, 2156, 233, 742, 400, 172, 329, 2377, 204, 1954, 2366, 1107, 1633, 2298, 621, 1590, 1350, 1478, 2333, 1361, 2323, 1681, 1601, 1300, 980, 1097, 1579, 1456, 1458, 1377, 1792, 1581, 1733, 1578, 1953, 323, 2159, 1881, 1836, 1654, 735, 756, 1262, 1921, 729, 2012, 1739, 861, 1174, 413, 480, 536, 781, 2266, 1957, 1849, 2402, 426, 1595, 1177, 1918, 643, 578, 1794, 1278, 1593, 1111, 2216, 2068, 2182, 912, 325, 2300, 1531, 1850, 206, 375, 113, 249, 1372, 663, 1599, 360, 181, 421, 1015, 1163, 20, 1504, 494, 1091, 250, 371, 1475, 1079, 500, 225, 218, 553, 427, 120, 457, 2373, 837, 519, 501, 634, 357, 17, 15, 1103, 2146, 1110, 771, 1731, 760, 1561, 2104, 2112, 772, 1045, 1218, 2255, 2164, 1971, 1715, 656, 1662, 1393, 2027, 310, 314, 1802, 1007, 392, 1080, 627, 1949, 2250, 529, 538, 1451, 2309, 971, 1763, 2257, 1757, 717, 944, 205, 491, 672, 694, 159, 2362, 659, 2244, 2169, 666, 929, 1710, 1046, 863, 1168, 445, 1981, 2153, 2186, 1228, 101, 580, 979, 354, 1975, 1057, 713, 1346, 967, 1275, 1026, 1992, 1190, 2363, 1636, 1321, 1901, 490, 1701, 1864, 706, 677, 2329, 2378, 2117, 1253, 1189, 2060, 2059, 1172, 98, 1818, 2352, 754, 795, 2133, 230, 1707, 150, 1477, 2026, 2399, 1074, 838, 70, 136, 1062, 1786, 69, 86, 1454, 495, 545, 1507, 2284, 307, 691, 239, 655, 274, 542, 1159, 931, 1973, 986, 2098, 1076, 452, 370, 882, 891, 757, 1644, 56, 1216, 2028, 1548, 746, 1354, 198, 587, 470, 2206, 417, 177, 477, 1106, 1917, 1251, 953, 436, 2101, 1187, 1674, 665, 1573, 1810, 1532, 2367, 970, 157, 461, 750, 770, 651, 551, 1202, 2180, 32, 65, 1358, 806, 66, 35, 1716, 2090, 1067, 2194, 901, 1344, 845, 2320, 1386, 1661, 1588, 903, 1493, 1042, 1824, 1339, 2118, 1233, 1381, 593, 1887, 1998, 1817, 2033, 1730, 1208, 1727, 812, 1812, 1813, 235, 1650, 505, 1405, 520, 1555, 1494, 2273, 569, 1804, 36, 1288, 532, 927, 60, 105, 698, 1908, 97, 411, 68, 1038, 890, 1471, 1587, 408, 2, 879, 1966, 818, 2205, 1833, 1422, 892, 2267, 1258, 1551, 161, 1128, 1753, 1441, 2203, 2214, 2142, 110, 1926, 2066, 1173, 373, 209, 300, 261, 165, 254, 1481, 1782, 650, 1418, 1656, 741, 1293, 918, 2217, 1819, 2123, 2105, 990, 1562, 1272, 840, 620, 2037, 210, 106, 743, 945, 1483, 1469, 1286, 1316, 1162, 1323, 1328, 1268, 402, 1407, 1858, 1364, 338, 1755, 2328, 1248, 1078, 182, 724, 55, 252, 2296, 447, 466, 1301, 1345, 358, 2029, 1925, 1905, 1890, 246, 1838, 654, 1203, 813, 2276, 2215, 1911, 862, 1935, 2338, 824, 1290, 1634, 1390, 1392, 2238, 2382, 972, 49, 1353, 398, 1220, 2128, 925, 2281, 2406, 1101, 889, 1564, 704, 1257, 2389, 779, 938, 854, 841, 1700, 1775, 995, 2303, 2395, 1958, 1296, 839, 388, 1511, 1784, 1736, 154, 2087, 81, 469, 1280, 1332, 1545, 664, 1892, 783, 433, 1436, 1610, 523, 1719, 816, 2240, 1660, 1846, 785, 363, 1967, 662, 1585, 1142, 479, 576, 77, 378, 260, 1891, 1065, 1283, 346, 214, 1265, 2099, 2357, 1230, 1523, 467, 301, 1878, 572, 339, 535, 2286, 823, 3, 1371, 872, 16, 53, 456, 2034, 766, 1909, 1261, 1577, 2316, 646, 153, 432, 2058, 1238, 2100, 1075, 1978, 1310, 2212, 1435, 1002, 922, 1987, 2054, 2390, 1855, 1841, 617, 332, 1798, 48, 1411, 804, 2036, 937, 478, 661, 1270, 1779, 1713, 2353, 1594, 1115, 149, 109, 1963, 739, 243, 2383, 1006, 1256, 2166, 1944, 847, 1769, 1797, 1072, 674, 1623, 2221, 2408, 2199, 1842, 789, 2297, 1409, 864, 1678, 1859, 287, 2188, 23, 62, 652, 1035, 152, 424, 100, 1857, 869, 1870, 2213, 1047, 2160, 825, 1093, 257, 584, 337, 1877, 45, 281, 631, 59, 1098, 1783, 2242, 1348, 685, 170, 571, 267, 550, 2282, 2295, 24, 328, 1528, 1771, 1108, 992, 1063, 1059, 2269, 1229, 1955, 1397, 1862, 1788, 1619, 2375, 1815, 1726, 2047, 1565, 1092, 1365, 2023, 900, 2008, 881, 530, 148, 228, 2070, 2318, 1359, 2134, 1898, 1679, 896, 512, 549, 472, 1292, 744, 977, 2306, 2137, 1583, 1241, 2045, 1401, 1378, 727, 1752, 185, 1309, 878, 296, 189, 2330, 2172, 1869, 2065, 290, 475, 1276, 1, 1028, 1865, 1552, 394, 843, 2207, 1017, 738, 46, 1803, 2116, 609, 455, 1830, 560, 367, 91, 156, 2283, 345, 2187, 263, 1986, 2127, 1615, 2057, 1453, 1622, 844, 1227, 1829, 2149, 527, 556, 95, 1651, 2211, 1652, 1114, 1653, 705, 1648, 492, 366, 324, 255, 1828, 830, 173, 1873, 1852, 1148, 220, 2145, 1643, 608, 1052, 1066, 2121, 853, 2239, 1498, 2011, 194, 217, 1014, 952, 1416, 1484, 2312, 1289, 393, 2171, 2335, 441, 443, 1765, 1180, 1938, 628, 2381, 894, 2102, 1625, 644, 761, 1069, 762, 800, 686, 1972, 1152, 1747, 460, 2345, 1452, 842, 2326, 2386, 958, 124, 2231, 1907, 2030, 1725, 1675, 2336, 2124, 2350, 13, 145, 280, 57, 1724, 893, 1684, 1745, 1259, 1492, 1704, 58, 1748, 1506, 948, 688, 1995, 745, 1096, 1019, 989, 1338, 624, 1443, 2210, 1571, 737, 1516, 215, 1343, 428, 1787, 276, 2407, 1315, 1563, 1021, 47, 1320, 622, 1984, 796, 2193, 1034, 21, 1592, 1770, 1737, 1134, 303, 258, 2120, 1116, 1805, 606, 1616, 581, 684, 1370, 1039, 2179, 715, 1430, 561, 2072, 174, 1664, 554, 726, 1023, 1298, 2307, 1646, 2225, 1539, 1723, 1240, 886, 1487, 1503, 2073, 1325, 1825, 166, 1720, 1669, 284, 585, 557, 331, 499, 541, 135, 906, 908, 1948, 1231, 111, 544, 192, 63, 88, 355, 1033, 1520, 1277, 2125, 1687, 2259, 923, 2024, 30, 40, 1734, 877, 1112, 1586, 1844, 859, 768, 1239, 733, 1919, 2191, 1455, 348, 997, 875, 2251, 485, 1940, 1417, 1083, 1333, 798, 112, 435, 242, 7, 2000, 1641, 1385, 2275, 1137, 987, 1744, 2327, 1016, 2371, 1990, 2132, 1598, 792, 1120, 43, 131, 227, 1176, 2234, 2019, 2272, 1132, 1721, 907, 2009, 365, 1847, 1146, 682, 873, 2202, 2262, 493, 1335, 1904, 857, 1086, 1245, 775, 1576, 75, 347, 1150, 1427, 231, 219, 716, 2143, 797, 1999, 386, 2078, 418, 868, 2016, 2271, 528, 176, 1009, 960, 1688, 993, 1743, 2111, 1626, 2201, 1837, 2387, 221, 1467, 2032, 619, 748, 1179, 888, 1255, 730, 2192, 676, 2265, 5, 811, 308, 1413, 2209, 183, 1793, 453, 1195, 1795, 454, 558, 2374, 1318, 1900, 2063, 1139, 1876, 2113, 90, 828, 692, 164, 2317, 1197, 1337, 1924, 2049, 1151, 602, 601, 87, 936, 11, 2305, 2347, 2376, 1526, 1811, 1930, 708, 2252, 61, 959, 197, 1138, 1144, 1913, 1447, 1479, 319, 118, 2094, 119, 939, 1746, 26, 1894, 1977, 1903, 273, 573, 1976, 1655, 1254, 1122, 1923, 2292, 856, 1366, 2232, 1209, 141, 265, 342, 1349, 1090, 2048, 547, 320, 1831, 1544, 2388, 1604, 2140, 2218, 1680, 2135, 1404, 2369, 1205, 2261, 1882, 2183, 645, 1127, 1473, 1095, 1433, 607, 1123, 1512, 1695, 1206, 2079, 678, 1306, 1207, 1191, 285, 171, 142, 459, 815, 1667, 134, 965, 1311, 1699, 589, 1363, 1304, 1284, 2364, 2093, 1169, 444, 1685, 2308, 1406, 1089, 253, 72, 935, 1470, 353, 831, 1628, 957, 2148, 740, 1125, 2013, 448, 94, 486, 1645, 1767, 876, 1886, 162, 2162, 1264, 954, 2010, 1671, 2157, 2189, 2092, 10, 1143, 1513, 599, 1421, 1624, 848, 2017, 223, 114, 1003, 1303, 397, 25, 1287, 1102, 1822, 1273, 592, 2108, 295, 442, 292, 247, 817, 1635, 2064, 2086, 1124, 1352, 1223, 1785, 384, 391, 1505, 1621, 1210, 667, 1040, 1606, 1632, 1884, 702, 905, 2301, 129, 200, 759, 752, 2096, 333, 83, 897, 2141, 1394, 2285, 1834, 640, 379, 80, 2220, 1403, 1449, 575, 2204, 1758, 1398, 669, 1237, 2130, 1013, 473, 1192, 1056, 709, 385, 321, 776, 2315, 1965, 1049, 376, 539, 1153, 2394, 2022, 747, 521, 208, 130, 860, 555, 1085, 224, 430, 414, 2031, 767, 2056, 502, 2355, 1424, 1772, 1147, 802, 1442, 1663, 961, 463, 1537, 966, 1388, 372, 76, 1964, 256, 565, 2245, 774, 1445, 1243, 1312, 1154, 1549, 1193, 639, 2243, 926, 245, 1308, 2088, 2085, 1694, 930, 160, 264, 2035, 1211, 1629, 471, 2279, 1728, 1213, 915, 349, 187, 241, 1070, 874, 2332, 2249, 438, 629, 2103, 690, 2175, 1011, 675, 1466, 1647, 1282, 67, 793, 671, 1491, 1542, 1212, 991, 1476, 18, 642, 2196, 2001, 765, 1242, 568, 128, 1432, 1410, 1791, 140, 2304, 1766, 1389, 104, 236, 516, 450, 420, 89, 22, 1982, 2155, 1570, 2007, 216, 318, 564, 563, 507, 508, 343, 1384, 964, 681, 2077, 546, 1387, 1121, 2174, 588, 1400, 1222, 710, 356, 1885, 2379, 653, 1457, 1060, 2052, 1402, 2393, 598, 1569, 2324, 2161, 1951, 2270, 934, 1893, 1773, 2197, 942, 1025, 1175, 808, 1022, 1426, 1165, 1232, 312, 484, 2302, 2233, 92, 34, 1947, 2274, 633, 2405, 1856, 1249, 44, 1750, 27, 4, 1235, 1871, 167, 2109, 1357, 2069, 778, 107, 270, 1929, 1735, 1961, 2227, 336, 108, 1756, 144, 476, 2314, 2392, 951, 188, 2107, 2223, 2038, 1591, 2278, 846, 791, 809, 2071, 2119, 2409, 458, 199, 899, 2184, 1347, 330, 415, 54, 322, 511, 1823, 1374, 1018, 268, 1541, 810, 680, 431, 362, 1215, 380, 1145, 2006, 1673, 1408, 1326, 826, 395, 79, 2280, 316, 317, 1000, 1920, 1883, 1906, 1611, 913, 911, 1821, 514, 440, 405, 1853, 2246, 2322, 2042, 1020, 1342, 670, 1751, 1760, 293, 1274, 1160, 605, 1835, 1741, 1580, 309, 71, 988, 1118, 2299, 425, 196, 340, 1324, 1295, 2173, 2170, 1496, 1117, 1603, 895, 2062, 590, 1631, 1608, 1800, 294, 125, 1609, 2154, 1600, 790, 2050, 1502, 2263, 1181, 2253, 311, 782, 515, 2321, 1158, 910, 773, 2131, 1472, 423, 374, 1221, 409, 102, 1064, 1167, 1297, 764, 2339, 138, 383, 434, 509, 351, 1061, 1879, 207, 359, 1317, 1843, 506, 278, 381, 410, 396, 446, 234, 2018, 1055, 2158, 462, 1801, 1941, 1554, 641, 8, 1234, 699, 579, 33, 422, 719, 2003, 226, 981, 1480, 1379, 1041, 1872, 211, 574, 133, 978, 1807, 1088, 2151, 1778, 1267, 297, 126, 1100, 222, 1279])\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer =  CountVectorizer(min_df=0, lowercase=False,stop_words='english') # will also remove punctuation or stop words\n",
    "vectorizer.fit(imdb_sentences_train)\n",
    "\n",
    "Imdb_X_train = vectorizer.transform(imdb_sentences_train).toarray()\n",
    "Imdb_X_test  = vectorizer.transform(imdb_sentences_test).toarray()\n",
    "\n",
    "print(\"Training matrix shape\", Imdb_X_train.shape)\n",
    "print(\"Testing matrix shape\", Imdb_X_test.shape)\n",
    "print(\"Vocabulary: \",vectorizer.vocabulary_)\n",
    "print(\"Vocabulary words: \",vectorizer.vocabulary_.keys())\n",
    "print(\"Vocabulary index: \",vectorizer.vocabulary_.values())\n",
    "print(Imdb_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htMRBiGRSOim"
   },
   "source": [
    "**Applying Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1A3ThyJjSIic",
    "outputId": "8b14fdb1-3845-431a-8aef-8e09eb8f594b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Imdb logistic model: 0.7486631016042781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(Imdb_X_train, imdb_y_train)\n",
    "score = logistic_classifier.score(Imdb_X_test, imdb_y_test)\n",
    "print(\"Accuracy of Imdb logistic model:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xf8ZFpwSXYP"
   },
   "source": [
    "**Applying Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-kZLZjPSb4Z",
    "outputId": "e66c926b-8f4d-4f48-def3-0986de7d61bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5377 - val_loss: 0.6861 - val_accuracy: 0.5965\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.8333 - val_loss: 0.6734 - val_accuracy: 0.7018\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.9127 - val_loss: 0.6675 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.9365 - val_loss: 0.6556 - val_accuracy: 0.6842\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.9464 - val_loss: 0.6458 - val_accuracy: 0.7018\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.9544 - val_loss: 0.6427 - val_accuracy: 0.7368\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.9623 - val_loss: 0.6331 - val_accuracy: 0.7544\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.9663 - val_loss: 0.6284 - val_accuracy: 0.7544\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.9702 - val_loss: 0.6236 - val_accuracy: 0.7719\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.9702 - val_loss: 0.6158 - val_accuracy: 0.7719\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9742 - val_loss: 0.6104 - val_accuracy: 0.7719\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.9742 - val_loss: 0.6067 - val_accuracy: 0.7719\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.9742 - val_loss: 0.6061 - val_accuracy: 0.7719\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.9742 - val_loss: 0.6001 - val_accuracy: 0.7895\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.9742 - val_loss: 0.6001 - val_accuracy: 0.7895\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.9742 - val_loss: 0.5980 - val_accuracy: 0.7895\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.9742 - val_loss: 0.5947 - val_accuracy: 0.8070\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.9762 - val_loss: 0.5931 - val_accuracy: 0.7895\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.9742 - val_loss: 0.5912 - val_accuracy: 0.7895\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.9742 - val_loss: 0.5902 - val_accuracy: 0.8070\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.9782 - val_loss: 0.5909 - val_accuracy: 0.8070\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.9802 - val_loss: 0.5870 - val_accuracy: 0.7895\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.9802 - val_loss: 0.5849 - val_accuracy: 0.7895\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.9802 - val_loss: 0.5839 - val_accuracy: 0.7895\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.9802 - val_loss: 0.5849 - val_accuracy: 0.7895\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.9821 - val_loss: 0.5852 - val_accuracy: 0.7895\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9821 - val_loss: 0.5816 - val_accuracy: 0.7895\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9841 - val_loss: 0.5819 - val_accuracy: 0.7895\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.9841 - val_loss: 0.5861 - val_accuracy: 0.7895\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2679 - accuracy: 0.9841 - val_loss: 0.5840 - val_accuracy: 0.7895\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.9841 - val_loss: 0.5830 - val_accuracy: 0.7895\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9861 - val_loss: 0.5815 - val_accuracy: 0.7895\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.9861 - val_loss: 0.5822 - val_accuracy: 0.7895\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9841 - val_loss: 0.5830 - val_accuracy: 0.7895\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9881 - val_loss: 0.5832 - val_accuracy: 0.7895\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9881 - val_loss: 0.5840 - val_accuracy: 0.7895\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9881 - val_loss: 0.5831 - val_accuracy: 0.7895\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9901 - val_loss: 0.5835 - val_accuracy: 0.7895\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9901 - val_loss: 0.5839 - val_accuracy: 0.7895\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2117 - accuracy: 0.9881 - val_loss: 0.5860 - val_accuracy: 0.7895\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9901 - val_loss: 0.5866 - val_accuracy: 0.7895\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9901 - val_loss: 0.5877 - val_accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dropout,Activation\n",
    "from keras.layers import BatchNormalization,Dense\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers,Sequential\n",
    "import numpy as np\n",
    "keras_callbacks   = [\n",
    "      EarlyStopping(monitor='val_loss', patience=10, mode='min', min_delta=0.0001),\n",
    "      ModelCheckpoint('./checkmodel.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "]\n",
    "\n",
    "def build_model(n_layers = 2, n_neurons = 1000,initializer='uniform'):\n",
    "  \n",
    "  if initializer == 'uniform':\n",
    "    w_in = np.sqrt(0.001)\n",
    "    initializer = initializers.RandomUniform(minval=-w_in, maxval=w_in)\n",
    "  else:\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal\n",
    "    initializer = initializers.glorot_normal()\n",
    "  \n",
    "  model = Sequential() # create Sequential model\n",
    "  for i in range(n_layers-1):\n",
    "      model.add(Dense(n_neurons, kernel_initializer=initializer))\n",
    "      model.add(BatchNormalization()) ## add batch normalization before activation\n",
    "      model.add(Activation('relu'))\n",
    "      model.add(Dropout(0.2))\n",
    "  model.add(Dense(1, activation = 'sigmoid', kernel_initializer=initializer)) \n",
    "  return model\n",
    "\n",
    "imdb_model = build_model(n_layers = 1, n_neurons = 10,initializer='uniform')\n",
    "imdb_model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "train_history_imdb = imdb_model.fit(Imdb_X_train,imdb_y_train, validation_split=0.1, batch_size = 5, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m70kl2rbSrSR",
    "outputId": "e4924daf-58a5-45d1-b990-e7bf9a66e8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7433\n",
      "Accuracy of Imdb neural network model: 0.7433155179023743\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Imdb neural network model:\", imdb_model.evaluate(Imdb_X_test, imdb_y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "dId2s15YSjM7",
    "outputId": "e8142a20-e982-4399-c227-6060e38eba10"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "# Plot training & validation loss values\n",
    "plt.plot(train_history_imdb.history['loss'], label='Train')\n",
    "plt.plot(train_history_imdb.history['val_loss'], label='Validation')\n",
    "plt.title('Training & Validation Loss', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.xticks( fontsize=12)\n",
    "plt.yticks( fontsize=12)\n",
    "plt.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(train_history_imdb.history['accuracy'], label='Train')\n",
    "plt.plot(train_history_imdb.history['val_accuracy'], label='Validation')\n",
    "plt.title('Training & Validation accuracy', fontsize=15)\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.xticks( fontsize=12)\n",
    "plt.yticks( fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0twIVP70VuTb"
   },
   "source": [
    "**Word Embedding: Rerepresent each word as a vector.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LCObVmfmvCk",
    "outputId": "178adc2a-bb4b-48c4-cf73-1be821bf3a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Give this one a look.  '\n",
      " 'In fact, this stinker smells like a direct-to-video release.  '\n",
      " 'Every single character was hilarious and deserved to be called a lead.  '\n",
      " 'This movie does an excellent job of revealing the complexity of the task and the incredible challenges facing South Africa.  '\n",
      " 'there are so many problems i dont know where to start.  ']\n",
      "[[7, 1, 8, 2, 9], [10, 11, 1, 12, 13, 14, 2, 15, 3, 16, 17], [18, 19, 20, 21, 22, 5, 23, 3, 24, 25, 2, 26], [1, 27, 28, 29, 30, 31, 6, 32, 4, 33, 6, 4, 34, 5, 4, 35, 36, 37, 38, 39], [40, 41, 42, 43, 44, 45, 46, 47, 48, 3, 49]]\n",
      "Word frequency: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 2,\n",
       " 'africa': 39,\n",
       " 'an': 29,\n",
       " 'and': 5,\n",
       " 'are': 41,\n",
       " 'be': 24,\n",
       " 'called': 25,\n",
       " 'challenges': 36,\n",
       " 'character': 20,\n",
       " 'complexity': 33,\n",
       " 'deserved': 23,\n",
       " 'direct': 15,\n",
       " 'does': 28,\n",
       " 'dont': 46,\n",
       " 'every': 18,\n",
       " 'excellent': 30,\n",
       " 'facing': 37,\n",
       " 'fact': 11,\n",
       " 'give': 7,\n",
       " 'hilarious': 22,\n",
       " 'i': 45,\n",
       " 'in': 10,\n",
       " 'incredible': 35,\n",
       " 'job': 31,\n",
       " 'know': 47,\n",
       " 'lead': 26,\n",
       " 'like': 14,\n",
       " 'look': 9,\n",
       " 'many': 43,\n",
       " 'movie': 27,\n",
       " 'of': 6,\n",
       " 'one': 8,\n",
       " 'problems': 44,\n",
       " 'release': 17,\n",
       " 'revealing': 32,\n",
       " 'single': 19,\n",
       " 'smells': 13,\n",
       " 'so': 42,\n",
       " 'south': 38,\n",
       " 'start': 49,\n",
       " 'stinker': 12,\n",
       " 'task': 34,\n",
       " 'the': 4,\n",
       " 'there': 40,\n",
       " 'this': 1,\n",
       " 'to': 3,\n",
       " 'video': 16,\n",
       " 'was': 21,\n",
       " 'where': 48}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000) \n",
    "tokenizer.fit_on_texts(imdb_sentences_train[0:5])\n",
    "\n",
    "Imdb_X_train = tokenizer.texts_to_sequences(imdb_sentences_train[0:5])\n",
    "print(imdb_sentences_train[0:5])\n",
    "print(Imdb_X_train)\n",
    "\n",
    "print(\"Word frequency: \")\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAvwBXNZWRLB"
   },
   "source": [
    "**Padding sequences to the same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeWIlNaVnCdN",
    "outputId": "e664286d-64c0-4030-93bf-181e52af687d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  1,  8,  2,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [10, 11,  1, 12, 13, 14,  2, 15,  3, 16, 17,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [18, 19, 20, 21, 22,  5, 23,  3, 24, 25,  2, 26,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 1, 27, 28, 29, 30, 31,  6, 32,  4, 33,  6,  4, 34,  5,  4, 35,\n",
       "        36, 37, 38, 39,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48,  3, 49,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100  # specify how long the sequences should be. This cuts sequences that exceed that number.\n",
    "Imdb_X_train_pad = pad_sequences(Imdb_X_train, padding='post', maxlen=maxlen)\n",
    "Imdb_X_test_pad = pad_sequences(Imdb_X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "Imdb_X_train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2MtlwGBnL7U",
    "outputId": "5446d4bf-52a5-46b7-a9f8-a1949982979d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165,   6,  23, ...,   0,   0,   0],\n",
       "       [ 10, 218,   6, ...,   0,   0,   0],\n",
       "       [104, 321,  75, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  7, 675,  78, ...,   0,   0,   0],\n",
       "       [  7, 118,  14, ...,   0,   0,   0],\n",
       "       [  7, 100, 105, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(imdb_sentences_train)\n",
    "\n",
    "Imdb_X_train = tokenizer.texts_to_sequences(imdb_sentences_train)\n",
    "Imdb_X_test = tokenizer.texts_to_sequences(imdb_sentences_test)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "Imdb_X_train_pad = pad_sequences(Imdb_X_train, padding='post', maxlen=maxlen)\n",
    "Imdb_X_test_pad = pad_sequences(Imdb_X_test, padding='post', maxlen=maxlen)\n",
    "Imdb_X_train_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMkRc0opWjor"
   },
   "source": [
    "**Feature generation option : one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2KfQn8J3njyF"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False,handle_unknown = 'ignore')\n",
    "\n",
    "all_labels = Imdb_X_train_pad.reshape(-1,)\n",
    "all_labels\n",
    "enc.fit(all_labels.reshape(len(all_labels),1))  \n",
    "\n",
    "Imdb_X_train_pad_onehot = []\n",
    "for sentence in Imdb_X_train_pad:\n",
    "    Imdb_X_train_pad_onehot.append(enc.transform(sentence.reshape(maxlen,1)))\n",
    "\n",
    "Imdb_X_test_pad_onehot = []\n",
    "for sentence in Imdb_X_test_pad:\n",
    "    Imdb_X_test_pad_onehot.append(enc.transform(sentence.reshape(maxlen,1)))\n",
    "\n",
    "Imdb_X_train_pad_onehot = np.asarray(Imdb_X_train_pad_onehot)\n",
    "Imdb_X_test_pad_onehot = np.asarray(Imdb_X_test_pad_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8lKIaFyozbZ",
    "outputId": "757218e2-01ab-49ea-fce2-f22e321afa96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (561, 100, 2254)\n",
      "test:  (187, 100, 2254)\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \",Imdb_X_train_pad_onehot.shape)\n",
    "print(\"test: \",Imdb_X_test_pad_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJOAuJk-o3gN",
    "outputId": "0b115772-a350-4eb8-b29c-7c4d90a9def8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (561, 225400)\n",
      "Testing matrix shape (187, 225400)\n"
     ]
    }
   ],
   "source": [
    "Imdb_X_data_flatten = Imdb_X_train_pad_onehot.reshape(Imdb_X_train_pad_onehot.shape[0],100*2254)\n",
    "Imdb_X_test_flatten = Imdb_X_test_pad_onehot.reshape(Imdb_X_test_pad_onehot.shape[0],100*2254)\n",
    "print(\"Training matrix shape\", Imdb_X_data_flatten.shape)\n",
    "print(\"Testing matrix shape\", Imdb_X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anlJV-lfpS2V",
    "outputId": "829bc5f5-4ae6-4568-e9fe-18d962f978aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 55s 1s/step - loss: 0.8207 - accuracy: 0.5655 - val_loss: 0.6982 - val_accuracy: 0.4561\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.4361 - accuracy: 0.8095 - val_loss: 0.7000 - val_accuracy: 0.5965\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.3079 - accuracy: 0.8889 - val_loss: 0.7833 - val_accuracy: 0.5965\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.2048 - accuracy: 0.9266 - val_loss: 0.9246 - val_accuracy: 0.6140\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.0960 - accuracy: 0.9683 - val_loss: 1.4558 - val_accuracy: 0.5965\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.1531 - accuracy: 0.9425 - val_loss: 1.0287 - val_accuracy: 0.5088\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.1667 - accuracy: 0.9444 - val_loss: 1.1197 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.1522 - accuracy: 0.9484 - val_loss: 1.9878 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.1303 - accuracy: 0.9464 - val_loss: 1.2322 - val_accuracy: 0.5263\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.1442 - accuracy: 0.9444 - val_loss: 2.3282 - val_accuracy: 0.5965\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 53s 1s/step - loss: 0.0779 - accuracy: 0.9782 - val_loss: 1.1611 - val_accuracy: 0.5789\n"
     ]
    }
   ],
   "source": [
    "model = build_model(n_layers = 5, n_neurons = 1000,initializer='uniform')\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "train_history = model.fit(Imdb_X_data_flatten,imdb_y_train, validation_split=0.1, batch_size = 10, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tj8q9T5BsbK_",
    "outputId": "92483c59-2b46-4765-a568-2e9a61622650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 590ms/step - loss: 1.3469 - accuracy: 0.5348\n",
      "Accuracy of neural network model: 0.5347593426704407\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of neural network model:\", model.evaluate(Imdb_X_test_flatten, imdb_y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_RZPyFasiBI",
    "outputId": "a036856e-ce10-4c3e-e249-a0ceda4fabb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 0.7268 - accuracy: 0.6190 - val_loss: 0.6883 - val_accuracy: 0.6491\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.1329 - accuracy: 0.9623 - val_loss: 0.6830 - val_accuracy: 0.6316\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 7s 145ms/step - loss: 0.0287 - accuracy: 0.9940 - val_loss: 0.6809 - val_accuracy: 0.5439\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.6755 - val_accuracy: 0.5614\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 7s 147ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.5965\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 7s 147ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.6140\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6311 - val_accuracy: 0.6140\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.6491\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 9.5716e-04 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6470 - val_accuracy: 0.6491\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 7s 145ms/step - loss: 8.3549e-04 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 5.6896e-04 - accuracy: 1.0000 - val_loss: 0.6656 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 5.9899e-04 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 4.5956e-04 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.7018\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 7s 145ms/step - loss: 6.7766e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.6842\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 7s 147ms/step - loss: 4.2748e-04 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.6842\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 3.4234e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.6842\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 7s 146ms/step - loss: 2.8190e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.6842\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D,GlobalMaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras.layers import Flatten,BatchNormalization,Dropout\n",
    "\n",
    "model = Sequential() # create Sequential model\n",
    "model.add(Conv1D(128, 5, input_shape=(100, 2254), activation = 'relu')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid')) \n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "train_history = model.fit(Imdb_X_train_pad_onehot,imdb_y_train, validation_split=0.1, batch_size = 10, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYgwJIGHtWxn",
    "outputId": "8884d60b-d11d-4d28-d87f-cd2924f462b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 139ms/step - loss: 0.6162 - accuracy: 0.7219\n",
      "Accuracy of neural network model: 0.7219251394271851\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of neural network model:\", model.evaluate(Imdb_X_test_pad_onehot, imdb_y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbkQrCZaW55g"
   },
   "source": [
    "**Word embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTJwn8A8uNTC",
    "outputId": "ae3208df-22af-4ef7-e802-c2141e14fcb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165,   6,  23, ...,   0,   0,   0],\n",
       "       [ 10, 218,   6, ...,   0,   0,   0],\n",
       "       [104, 321,  75, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  7, 675,  78, ...,   0,   0,   0],\n",
       "       [  7, 118,  14, ...,   0,   0,   0],\n",
       "       [  7, 100, 105, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(imdb_sentences_train)\n",
    "\n",
    "Imdb_X_train = tokenizer.texts_to_sequences(imdb_sentences_train)\n",
    "Imdb_X_test = tokenizer.texts_to_sequences(imdb_sentences_test)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "Imdb_X_train_pad = pad_sequences(Imdb_X_train, padding='post', maxlen=maxlen)\n",
    "Imdb_test_pad = pad_sequences(Imdb_X_test, padding='post', maxlen=maxlen)\n",
    "Imdb_X_train_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxyt_jE_XGBz"
   },
   "source": [
    "**Using word embedding in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67XeWNTCvMrW",
    "outputId": "554edcf0-9027-4464-dedf-b907c990d0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 50)           124750    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 125,271\n",
      "Trainable params: 125,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 # addition value 0 for padding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen,\n",
    "                           embeddings_initializer=None)) ## Set embeddings_initializer to some other pre-trained weights for transfer learning\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuLK8oOhvRXh",
    "outputId": "53279bef-3af4-4782-888b-ce62ab297f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6903 - val_accuracy: 0.5789\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.9028 - val_loss: 0.6796 - val_accuracy: 0.6842\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.9087 - val_loss: 0.6593 - val_accuracy: 0.7544\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.9405 - val_loss: 0.6213 - val_accuracy: 0.8070\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.9742 - val_loss: 0.5776 - val_accuracy: 0.7895\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.9802 - val_loss: 0.5251 - val_accuracy: 0.8246\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9861 - val_loss: 0.4861 - val_accuracy: 0.8070\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9901 - val_loss: 0.4657 - val_accuracy: 0.8246\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0963 - accuracy: 0.9921 - val_loss: 0.4527 - val_accuracy: 0.8246\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9960 - val_loss: 0.4461 - val_accuracy: 0.8246\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9980 - val_loss: 0.4429 - val_accuracy: 0.8246\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9980 - val_loss: 0.4508 - val_accuracy: 0.8246\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.4544 - val_accuracy: 0.8246\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.8246\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.7895\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.7895\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.7895\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.7719\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.7895\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Imdb_X_train_pad, imdb_y_train, epochs=20, verbose=True, validation_split=0.1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sd009TK-vXLe",
    "outputId": "95d97fc8-06b7-411e-efd1-40f21e48e216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9768\n",
      "Testing Accuracy:  0.7487\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Imdb_X_train_pad, imdb_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(Imdb_X_test_pad, imdb_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cwAXxlbXTvF"
   },
   "source": [
    "**Add 1D convolutional neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oljRSnpEvgcQ",
    "outputId": "2e0b6343-63c6-47c1-ff34-848855d187b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 0.6764 - accuracy: 0.5774 - val_loss: 0.6896 - val_accuracy: 0.5789\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.1497 - accuracy: 0.9881 - val_loss: 0.6803 - val_accuracy: 0.7368\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.6842\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.6842\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.7193\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.7018\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.7544\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.7368\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.7368\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.7368\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.7368\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.7368\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.7368\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.7368\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.7368\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.7368\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.7368\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.4838e-04 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.7368\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.3382e-04 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.7368\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.7079e-04 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.7368\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.8623e-04 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.7368\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D,GlobalMaxPooling1D,MaxPooling1D \n",
    "from keras import regularizers\n",
    "from keras.layers import Flatten,BatchNormalization,Dropout\n",
    "\n",
    "model = Sequential() # create Sequential model\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "\n",
    "model.add(Conv1D(64, 5, input_shape=(maxlen, embedding_dim), activation = 'relu')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid')) \n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "train_history = model.fit(Imdb_X_train_pad,imdb_y_train, validation_split=0.1, batch_size = 10, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M638WEFDvmyv",
    "outputId": "246155ce-c311-4f9a-84c2-468423fbb6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           124750    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 96, 64)            16064     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 96, 64)            256       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,135\n",
      "Trainable params: 141,007\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvJPcdYOvqcM",
    "outputId": "c547abbe-1108-4621-ad6c-1ddca6278bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9733\n",
      "Testing Accuracy:  0.6631\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Imdb_X_train_pad, imdb_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(Imdb_X_test_pad, imdb_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rlTjfbfXill"
   },
   "source": [
    "**Recurrent Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ELbc7BDYfiO"
   },
   "source": [
    "**Architecture 1: Embedding + LSTM layer + Sigmoid classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeiafLE7v66G",
    "outputId": "74dee159-789e-499e-e966-67885ef55a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 50)           124750    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 185,251\n",
      "Trainable params: 185,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reshape the data and preparing to train\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(imdb_sentences_train)\n",
    "\n",
    "Imdb_X_train = tokenizer.texts_to_sequences(imdb_sentences_train)\n",
    "Imdb_X_test = tokenizer.texts_to_sequences(imdb_sentences_test)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "Imdb_X_train_pad = pad_sequences(Imdb_X_train, maxlen=maxlen)\n",
    "Imdb_X_test_pad = pad_sequences(Imdb_X_test, maxlen=maxlen)\n",
    "Imdb_X_train_pad\n",
    "\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 # addition value 0 for padding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.1))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qfg74NZVwAow",
    "outputId": "dd67b06a-910d-4cd4-d063-7361e2d820a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 5s 176ms/step - loss: 0.6922 - accuracy: 0.5079 - val_loss: 0.6898 - val_accuracy: 0.5263\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.6624 - accuracy: 0.6548 - val_loss: 0.6620 - val_accuracy: 0.6491\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 1.5631 - accuracy: 0.6210 - val_loss: 1.9661 - val_accuracy: 0.6140\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.8805 - accuracy: 0.7440 - val_loss: 0.7002 - val_accuracy: 0.4561\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.4866 - accuracy: 0.8690 - val_loss: 0.6242 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 4s 173ms/step - loss: 0.3085 - accuracy: 0.9425 - val_loss: 0.6684 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.1729 - accuracy: 0.9603 - val_loss: 0.5230 - val_accuracy: 0.8421\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.1166 - accuracy: 0.9722 - val_loss: 0.6280 - val_accuracy: 0.7018\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.0865 - accuracy: 0.9861 - val_loss: 0.7592 - val_accuracy: 0.7368\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 4s 173ms/step - loss: 0.0673 - accuracy: 0.9921 - val_loss: 0.8237 - val_accuracy: 0.6140\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.1287 - accuracy: 0.9544 - val_loss: 0.8243 - val_accuracy: 0.7193\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.0685 - accuracy: 0.9881 - val_loss: 0.6720 - val_accuracy: 0.7368\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.0414 - accuracy: 0.9940 - val_loss: 0.7444 - val_accuracy: 0.7719\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0404 - accuracy: 0.9960 - val_loss: 0.6177 - val_accuracy: 0.7895\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 4s 169ms/step - loss: 0.0286 - accuracy: 0.9980 - val_loss: 0.6738 - val_accuracy: 0.7719\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.0207 - accuracy: 0.9980 - val_loss: 0.7218 - val_accuracy: 0.7719\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 5s 173ms/step - loss: 0.0231 - accuracy: 0.9980 - val_loss: 1.1232 - val_accuracy: 0.5614\n"
     ]
    }
   ],
   "source": [
    "data=Imdb_X_train_pad.reshape(len(Imdb_X_train_pad),maxlen,1)\n",
    "\n",
    "train_history = model.fit(Imdb_X_train_pad,imdb_y_train, validation_split=0.1, batch_size = 20, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kXsgIQuwYlt",
    "outputId": "629d3103-36fb-465c-df86-3928fc17810a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9519\n",
      "Testing Accuracy:  0.6898\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Imdb_X_train_pad, imdb_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(Imdb_X_test_pad, imdb_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIWWHUHHZBD0"
   },
   "source": [
    "**Architecture 2: Embedding + LSTM  + Sigmoid classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-tAfbGewcew",
    "outputId": "80ebb417-7373-48fc-8e10-830ad9fc3783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 20s 391ms/step - loss: 0.6909 - accuracy: 0.5456 - val_loss: 0.6838 - val_accuracy: 0.5439\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 20s 384ms/step - loss: 0.6567 - accuracy: 0.6548 - val_loss: 0.6276 - val_accuracy: 0.6316\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 20s 383ms/step - loss: 0.4043 - accuracy: 0.8750 - val_loss: 0.7251 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 20s 383ms/step - loss: 0.2899 - accuracy: 0.9147 - val_loss: 0.6550 - val_accuracy: 0.6140\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 20s 383ms/step - loss: 0.1970 - accuracy: 0.9603 - val_loss: 0.6809 - val_accuracy: 0.7193\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 20s 390ms/step - loss: 0.0884 - accuracy: 0.9881 - val_loss: 0.7879 - val_accuracy: 0.7368\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 20s 387ms/step - loss: 0.0443 - accuracy: 0.9940 - val_loss: 0.8236 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 20s 386ms/step - loss: 0.0257 - accuracy: 0.9980 - val_loss: 0.9476 - val_accuracy: 0.7018\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 20s 383ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 0.9913 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 20s 387ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.0383 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 22s 430ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 1.0749 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 20s 385ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 1.2862 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D,GlobalMaxPooling1D,MaxPooling1D \n",
    "from keras import regularizers\n",
    "from keras.layers import Flatten,BatchNormalization,Dropout\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "keras_callbacks   = [\n",
    "      EarlyStopping(monitor='val_loss', patience=10, mode='min', min_delta=0.0001),\n",
    "      ModelCheckpoint('./checkmodel.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "]\n",
    "\n",
    "\n",
    "model = Sequential() # create Sequential model\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(LSTM(200,dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid')) \n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "train_history = model.fit(Imdb_X_train_pad,imdb_y_train, validation_split=0.1, batch_size = 10, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4no_4Q4wr1H",
    "outputId": "150875a9-a720-4386-ead2-982455d3a2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9661\n",
      "Testing Accuracy:  0.6898\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Imdb_X_train_pad, imdb_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(Imdb_X_test_pad, imdb_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UynbhxTIZJrz"
   },
   "source": [
    "**Architecture 3: Embedding + MaxPooling + LSTM layer + Sigmoid classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uADMj-0Rw7sc",
    "outputId": "f931584d-2286-4910-9809-11e7f2e89f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 30)           74850     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30)                3840      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 78,721\n",
      "Trainable params: 78,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Reshape\n",
    "\n",
    "embedding_dim = 30\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 # addition value 0 for padding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(Reshape((embedding_dim,1)))\n",
    "model.add(LSTM(30, dropout=0.3, recurrent_dropout=0.1))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X43wLTYjw82c",
    "outputId": "076ae3cf-07d3-4608-e8ba-5192bc2624fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.6934 - accuracy: 0.4921 - val_loss: 0.6899 - val_accuracy: 0.6140\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.6927 - accuracy: 0.5159 - val_loss: 0.6883 - val_accuracy: 0.6140\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.6918 - accuracy: 0.5159 - val_loss: 0.6845 - val_accuracy: 0.6140\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.6326 - accuracy: 0.6786 - val_loss: 0.6403 - val_accuracy: 0.6316\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.5367 - accuracy: 0.7401 - val_loss: 0.6107 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.4680 - accuracy: 0.7976 - val_loss: 0.6251 - val_accuracy: 0.7018\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.3725 - accuracy: 0.8472 - val_loss: 0.6461 - val_accuracy: 0.7018\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.3068 - accuracy: 0.8889 - val_loss: 0.6187 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.2496 - accuracy: 0.9087 - val_loss: 0.8233 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.2101 - accuracy: 0.9306 - val_loss: 0.6765 - val_accuracy: 0.6842\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.1801 - accuracy: 0.9444 - val_loss: 0.6789 - val_accuracy: 0.7368\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.1685 - accuracy: 0.9464 - val_loss: 0.7886 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.1793 - accuracy: 0.9425 - val_loss: 0.7360 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.1318 - accuracy: 0.9563 - val_loss: 0.8923 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.1450 - accuracy: 0.9544 - val_loss: 0.8162 - val_accuracy: 0.7018\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(Imdb_X_train_pad,imdb_y_train, validation_split=0.1, batch_size = 10, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUQJ0ANZ7fVs",
    "outputId": "f9bd02bf-d44b-4f02-af96-fceca7a88add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9519\n",
      "Testing Accuracy:  0.6738\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Imdb_X_train_pad, imdb_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(Imdb_X_test_pad, imdb_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pls65Zy7ZRnH"
   },
   "source": [
    "**Architecture 4: Embedding + Conv1D+ LSTM layer + Sigmoid classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBB9yvzp7qHu",
    "outputId": "bb3c6e44-e3f9-4147-9892-d051d208e50b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 30)           74850     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 100, 30)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 100, 64)           9664      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 25, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 150,615\n",
      "Trainable params: 150,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Reshape,SpatialDropout1D\n",
    "\n",
    "embedding_dim = 30\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 # addition value 0 for padding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Conv1D(activation=\"relu\", padding=\"same\", filters=64, kernel_size=5))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkQsgEKa7u0b",
    "outputId": "bddaaded-8791-4d3a-e3de-128b988abc0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 3s 53ms/step - loss: 0.6955 - accuracy: 0.5060 - val_loss: 0.6784 - val_accuracy: 0.6140\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.6848 - accuracy: 0.5298 - val_loss: 0.6665 - val_accuracy: 0.5614\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.5833 - accuracy: 0.7262 - val_loss: 0.6220 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 0.2895 - accuracy: 0.8929 - val_loss: 0.5613 - val_accuracy: 0.7719\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0962 - accuracy: 0.9742 - val_loss: 0.6536 - val_accuracy: 0.7895\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 0.0521 - accuracy: 0.9901 - val_loss: 0.7023 - val_accuracy: 0.7895\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 0.0252 - accuracy: 0.9960 - val_loss: 0.8283 - val_accuracy: 0.8246\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 0.8670 - val_accuracy: 0.8070\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.9692 - val_accuracy: 0.8421\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.9791 - val_accuracy: 0.7544\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0758 - val_accuracy: 0.7895\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 1.0776 - val_accuracy: 0.8070\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1462 - val_accuracy: 0.8070\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(Imdb_X_train_pad,imdb_y_train, validation_split=0.1, batch_size = 10, epochs = 50, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8PaxgZL8Bu3",
    "outputId": "f2052a33-d433-409f-8e08-ee9128041613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9768\n",
      "Testing Accuracy:  0.7219\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Imdb_X_train_pad, imdb_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(Imdb_X_test_pad, imdb_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework08_Imdb_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
